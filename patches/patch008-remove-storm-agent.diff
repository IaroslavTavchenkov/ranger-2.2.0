diff --git a/pom.xml b/pom.xml
index e084ad1df..9dcff2a51 100644
--- a/pom.xml
+++ b/pom.xml
@@ -245,7 +245,6 @@
                 <module>hdfs-agent</module>
                 <module>hive-agent</module>
                 <module>knox-agent</module>
-                <module>storm-agent</module>
                 <module>plugin-yarn</module>
                 <module>plugin-ozone</module>
                 <module>security-admin</module>
@@ -356,20 +355,6 @@
                 <module>ranger-knox-plugin-shim</module>
             </modules>
         </profile>
-        <profile>
-            <id>ranger-storm-plugin</id>
-            <modules>
-                <module>agents-audit</module>
-                <module>agents-common</module>
-                <module>agents-cred</module>
-                <module>agents-installer</module>
-                <module>credentialbuilder</module>
-                <module>ranger-plugin-classloader</module>
-                <module>ranger-util</module>
-                <module>storm-agent</module>
-                <module>ranger-storm-plugin-shim</module>
-            </modules>
-        </profile>
         <profile>
             <id>ranger-yarn-plugin</id>
             <modules>
@@ -531,7 +516,6 @@
                 <module>hdfs-agent</module>
                 <module>hive-agent</module>
                 <module>knox-agent</module>
-                <module>storm-agent</module>
                 <module>plugin-yarn</module>
                 <module>plugin-ozone</module>
                 <module>security-admin</module>
@@ -615,7 +599,6 @@
                 <module>hdfs-agent</module>
                 <module>hive-agent</module>
                 <module>knox-agent</module>
-                <module>storm-agent</module>
                 <module>plugin-yarn</module>
                 <module>plugin-ozone</module>
                 <module>security-admin</module>
diff --git a/storm-agent/.gitignore b/storm-agent/.gitignore
deleted file mode 100644
index 4a3ed53f7..000000000
--- a/storm-agent/.gitignore
+++ /dev/null
@@ -1,5 +0,0 @@
-/target/
-/bin/
-/bin/
-/target
-.settings/
diff --git a/storm-agent/conf/ranger-policymgr-ssl-changes.cfg b/storm-agent/conf/ranger-policymgr-ssl-changes.cfg
deleted file mode 100644
index 47126492f..000000000
--- a/storm-agent/conf/ranger-policymgr-ssl-changes.cfg
+++ /dev/null
@@ -1,21 +0,0 @@
-# Licensed to the Apache Software Foundation (ASF) under one or more
-# contributor license agreements.  See the NOTICE file distributed with
-# this work for additional information regarding copyright ownership.
-# The ASF licenses this file to You under the Apache License, Version 2.0
-# (the "License"); you may not use this file except in compliance with
-# the License.  You may obtain a copy of the License at
-#
-#     http://www.apache.org/licenses/LICENSE-2.0
-#
-# Unless required by applicable law or agreed to in writing, software
-# distributed under the License is distributed on an "AS IS" BASIS,
-# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-# See the License for the specific language governing permissions and
-# limitations under the License.
-#
-# SSL Params
-#
-xasecure.policymgr.clientssl.keystore					 %SSL_KEYSTORE_FILE_PATH%						mod create-if-not-exists
-xasecure.policymgr.clientssl.keystore.credential.file	 jceks://file%CREDENTIAL_PROVIDER_FILE%			mod create-if-not-exists
-xasecure.policymgr.clientssl.truststore				     %SSL_TRUSTSTORE_FILE_PATH%						mod create-if-not-exists
-xasecure.policymgr.clientssl.truststore.credential.file  jceks://file%CREDENTIAL_PROVIDER_FILE%         mod create-if-not-exists	
\ No newline at end of file
diff --git a/storm-agent/conf/ranger-policymgr-ssl.xml b/storm-agent/conf/ranger-policymgr-ssl.xml
deleted file mode 100644
index 3baf7725c..000000000
--- a/storm-agent/conf/ranger-policymgr-ssl.xml
+++ /dev/null
@@ -1,49 +0,0 @@
-<?xml version="1.0"?>
-<!--
-  Licensed to the Apache Software Foundation (ASF) under one or more
-  contributor license agreements.  See the NOTICE file distributed with
-  this work for additional information regarding copyright ownership.
-  The ASF licenses this file to You under the Apache License, Version 2.0
-  (the "License"); you may not use this file except in compliance with
-  the License.  You may obtain a copy of the License at
-
-      http://www.apache.org/licenses/LICENSE-2.0
-
-  Unless required by applicable law or agreed to in writing, software
-  distributed under the License is distributed on an "AS IS" BASIS,
-  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-  See the License for the specific language governing permissions and
-  limitations under the License.
--->
-<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
-<configuration xmlns:xi="http://www.w3.org/2001/XInclude">
-	<!--  The following properties are used for 2-way SSL client server validation -->
-	<property>
-		<name>xasecure.policymgr.clientssl.keystore</name>
-		<value>hadoopdev-clientcert.jks</value>
-		<description> 
-			Java Keystore files 
-		</description>
-	</property>
-	<property>
-		<name>xasecure.policymgr.clientssl.truststore</name>
-		<value>cacerts-xasecure.jks</value>
-		<description> 
-			java truststore file
-		</description>
-	</property>
-    <property>
-		<name>xasecure.policymgr.clientssl.keystore.credential.file</name>
-		<value>jceks://file/tmp/keystore-hadoopdev-ssl.jceks</value>
-		<description> 
-			java  keystore credential file
-		</description>
-	</property>
-	<property>
-		<name>xasecure.policymgr.clientssl.truststore.credential.file</name>
-		<value>jceks://file/tmp/truststore-hadoopdev-ssl.jceks</value>
-		<description> 
-			java  truststore credential file
-		</description>
-	</property>
-</configuration>
\ No newline at end of file
diff --git a/storm-agent/conf/ranger-storm-audit-changes.cfg b/storm-agent/conf/ranger-storm-audit-changes.cfg
deleted file mode 100644
index c396d5d55..000000000
--- a/storm-agent/conf/ranger-storm-audit-changes.cfg
+++ /dev/null
@@ -1,75 +0,0 @@
-# Licensed to the Apache Software Foundation (ASF) under one or more
-# contributor license agreements.  See the NOTICE file distributed with
-# this work for additional information regarding copyright ownership.
-# The ASF licenses this file to You under the Apache License, Version 2.0
-# (the "License"); you may not use this file except in compliance with
-# the License.  You may obtain a copy of the License at
-#
-#     http://www.apache.org/licenses/LICENSE-2.0
-#
-# Unless required by applicable law or agreed to in writing, software
-# distributed under the License is distributed on an "AS IS" BASIS,
-# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-# See the License for the specific language governing permissions and
-# limitations under the License.
-
-xasecure.audit.hdfs.is.enabled                                     %XAAUDIT.HDFS.IS_ENABLED%                               mod create-if-not-exists
-xasecure.audit.hdfs.config.destination.directory                   %XAAUDIT.HDFS.DESTINATION_DIRECTORY%                    mod create-if-not-exists
-xasecure.audit.hdfs.config.destination.file                        %XAAUDIT.HDFS.DESTINTATION_FILE%                        mod create-if-not-exists
-xasecure.audit.hdfs.config.destination.flush.interval.seconds      %XAAUDIT.HDFS.DESTINTATION_FLUSH_INTERVAL_SECONDS%      mod create-if-not-exists
-xasecure.audit.hdfs.config.destination.rollover.interval.seconds   %XAAUDIT.HDFS.DESTINTATION_ROLLOVER_INTERVAL_SECONDS%   mod create-if-not-exists
-xasecure.audit.hdfs.config.destination.open.retry.interval.seconds %XAAUDIT.HDFS.DESTINTATION_OPEN_RETRY_INTERVAL_SECONDS% mod create-if-not-exists
-xasecure.audit.hdfs.config.local.buffer.directory                  %XAAUDIT.HDFS.LOCAL_BUFFER_DIRECTORY%                   mod create-if-not-exists
-xasecure.audit.hdfs.config.local.buffer.file                       %XAAUDIT.HDFS.LOCAL_BUFFER_FILE%                        mod create-if-not-exists
-xasecure.audit.hdfs.config.local.buffer.flush.interval.seconds     %XAAUDIT.HDFS.LOCAL_BUFFER_FLUSH_INTERVAL_SECONDS%      mod create-if-not-exists
-xasecure.audit.hdfs.config.local.buffer.rollover.interval.seconds  %XAAUDIT.HDFS.LOCAL_BUFFER_ROLLOVER_INTERVAL_SECONDS%   mod create-if-not-exists
-xasecure.audit.hdfs.config.local.archive.directory                 %XAAUDIT.HDFS.LOCAL_ARCHIVE_DIRECTORY%                  mod create-if-not-exists
-xasecure.audit.hdfs.config.local.archive.max.file.count            %XAAUDIT.HDFS.LOCAL_ARCHIVE_MAX_FILE_COUNT%             mod create-if-not-exists
-
-#xasecure.audit.kafka.is.enabled                                    %XAAUDIT.KAFKA.IS_ENABLED%                             mod create-if-not-exists
-#xasecure.audit.kafka.is.async                                      %XAAUDIT.KAFKA.IS_ASYNC%                               mod create-if-not-exists
-#xasecure.audit.kafka.async.max.queue.size                          %XAAUDIT.KAFKA.MAX_QUEUE_SIZE%                         mod create-if-not-exists
-#xasecure.audit.kafka.async.max.flush.interval.ms                   %XAAUDIT.KAFKA.MAX_FLUSH_INTERVAL_MS%                  mod create-if-not-exists
-#xasecure.audit.kafka.broker_list                                   %XAAUDIT.KAFKA.BROKER_LIST%                            mod create-if-not-exists
-#xasecure.audit.kafka.topic_name                                    %XAAUDIT.KAFKA.TOPIC_NAME%                             mod create-if-not-exists
-
-xasecure.audit.solr.is.enabled                                    %XAAUDIT.SOLR.IS_ENABLED%                               mod create-if-not-exists
-xasecure.audit.solr.async.max.queue.size                          %XAAUDIT.SOLR.MAX_QUEUE_SIZE%                           mod create-if-not-exists
-xasecure.audit.solr.async.max.flush.interval.ms                   %XAAUDIT.SOLR.MAX_FLUSH_INTERVAL_MS%                    mod create-if-not-exists
-xasecure.audit.solr.solr_url                                      %XAAUDIT.SOLR.SOLR_URL%                                 mod create-if-not-exists
-
-#V3 configuration
-xasecure.audit.destination.solr                                    %XAAUDIT.SOLR.ENABLE%                               mod create-if-not-exists
-xasecure.audit.destination.solr.urls                               %XAAUDIT.SOLR.URL%                                 mod create-if-not-exists
-xasecure.audit.destination.solr.user %XAAUDIT.SOLR.USER% mod create-if-not-exists
-xasecure.audit.destination.solr.password %XAAUDIT.SOLR.PASSWORD% mod create-if-not-exists
-xasecure.audit.destination.solr.zookeepers                         %XAAUDIT.SOLR.ZOOKEEPER%                           mod create-if-not-exists
-xasecure.audit.destination.solr.batch.filespool.dir                %XAAUDIT.SOLR.FILE_SPOOL_DIR%                      mod create-if-not-exists
-
-xasecure.audit.destination.elasticsearch                                    %XAAUDIT.ELASTICSEARCH.ENABLE%                              mod create-if-not-exists
-xasecure.audit.destination.elasticsearch.urls                               %XAAUDIT.ELASTICSEARCH.URL%                                 mod create-if-not-exists
-xasecure.audit.destination.elasticsearch.user 							   %XAAUDIT.ELASTICSEARCH.USER% 								  mod create-if-not-exists
-xasecure.audit.destination.elasticsearch.password 						   %XAAUDIT.ELASTICSEARCH.PASSWORD% 							  mod create-if-not-exists
-xasecure.audit.destination.elasticsearch.index 						   %XAAUDIT.ELASTICSEARCH.INDEX% 							  mod create-if-not-exists
-xasecure.audit.destination.elasticsearch.port 						   %XAAUDIT.ELASTICSEARCH.PORT% 							  mod create-if-not-exists
-xasecure.audit.destination.elasticsearch.protocol 						   %XAAUDIT.ELASTICSEARCH.PROTOCOL% 							  mod create-if-not-exists
-
-xasecure.audit.destination.hdfs					   %XAAUDIT.HDFS.ENABLE%                      mod create-if-not-exists
-xasecure.audit.destination.hdfs.batch.filespool.dir                %XAAUDIT.HDFS.FILE_SPOOL_DIR%                      mod create-if-not-exists
-xasecure.audit.destination.hdfs.dir                		   %XAAUDIT.HDFS.HDFS_DIR%                      mod create-if-not-exists
-
-AZURE.ACCOUNTNAME                                                                                                 %XAAUDIT.HDFS.AZURE_ACCOUNTNAME%            var
-xasecure.audit.destination.hdfs.config.fs.azure.shellkeyprovider.script                                           %XAAUDIT.HDFS.AZURE_SHELL_KEY_PROVIDER%     mod         create-if-not-exists
-xasecure.audit.destination.hdfs.config.fs.azure.account.key.%AZURE.ACCOUNTNAME%.blob.core.windows.net             %XAAUDIT.HDFS.AZURE_ACCOUNTKEY%             mod         create-if-not-exists
-xasecure.audit.destination.hdfs.config.fs.azure.account.keyprovider.%AZURE.ACCOUNTNAME%.blob.core.windows.net     %XAAUDIT.HDFS.AZURE_ACCOUNTKEY_PROVIDER%    mod         create-if-not-exists
-
-#xasecure.audit.destination.file					   %XAAUDIT.FILE.ENABLE%                      mod create-if-not-exists
-#xasecure.audit.destination.file.dir                		   %XAAUDIT.FILE.DIR%                      mod create-if-not-exists
-
-#log4j configuration
-xasecure.audit.log4j.is.enabled                %XAAUDIT.LOG4J.ENABLE%                      mod create-if-not-exists
-xasecure.audit.log4j.is.async                %XAAUDIT.LOG4J.IS_ASYNC%                      mod create-if-not-exists
-xasecure.audit.log4j.async.max.queue.size                %XAAUDIT.LOG4J.ASYNC.MAX.QUEUE.SIZE%                      mod create-if-not-exists
-xasecure.audit.log4j.async.max.flush.interval.ms                %XAAUDIT.LOG4J.ASYNC.MAX.FLUSH.INTERVAL.MS%                      mod create-if-not-exists
-xasecure.audit.destination.log4j                %XAAUDIT.LOG4J.DESTINATION.LOG4J%                      mod create-if-not-exists
-xasecure.audit.destination.log4j.logger                %XAAUDIT.LOG4J.DESTINATION.LOG4J.LOGGER%                      mod create-if-not-exists
diff --git a/storm-agent/conf/ranger-storm-audit.xml b/storm-agent/conf/ranger-storm-audit.xml
deleted file mode 100644
index 80232dbd6..000000000
--- a/storm-agent/conf/ranger-storm-audit.xml
+++ /dev/null
@@ -1,216 +0,0 @@
-<?xml version="1.0"?>
-<!--
-  Licensed to the Apache Software Foundation (ASF) under one or more
-  contributor license agreements.  See the NOTICE file distributed with
-  this work for additional information regarding copyright ownership.
-  The ASF licenses this file to You under the Apache License, Version 2.0
-  (the "License"); you may not use this file except in compliance with
-  the License.  You may obtain a copy of the License at
-
-      http://www.apache.org/licenses/LICENSE-2.0
-
-  Unless required by applicable law or agreed to in writing, software
-  distributed under the License is distributed on an "AS IS" BASIS,
-  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-  See the License for the specific language governing permissions and
-  limitations under the License.
--->
-<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
-<configuration xmlns:xi="http://www.w3.org/2001/XInclude">
-	<property>
-		<name>xasecure.audit.is.enabled</name>
-		<value>true</value>
-	</property>	
-
-	<!-- HDFS audit provider configuration -->
-	<property>
-		<name>xasecure.audit.hdfs.is.enabled</name>
-		<value>false</value>
-	</property>	
-
-	<property>
-		<name>xasecure.audit.hdfs.is.async</name>
-		<value>true</value>
-	</property>	
-	
-	<property>
-		<name>xasecure.audit.hdfs.async.max.queue.size</name>
-		<value>1048576</value>
-	</property>	
-
-	<property>
-		<name>xasecure.audit.hdfs.async.max.flush.interval.ms</name>
-		<value>30000</value>
-	</property>	
-
-	<property>
-		<name>xasecure.audit.hdfs.config.encoding</name>
-		<value></value>
-	</property>	
-
-	<property>
-		<name>xasecure.audit.hdfs.config.destination.directory</name>
-		<value>hdfs://NAMENODE_HOST:8020/ranger/audit/%app-type%/%time:yyyyMMdd%</value>
-	</property>	
-
-	<property>
-		<name>xasecure.audit.hdfs.config.destination.file</name>
-		<value>%hostname%-audit.log</value>
-	</property>	
-
-	<property>
-		<name>xasecure.audit.hdfs.config.destination.flush.interval.seconds</name>
-		<value>900</value>
-	</property>	
-
-	<property>
-		<name>xasecure.audit.hdfs.config.destination.rollover.interval.seconds</name>
-		<value>86400</value>
-	</property>	
-
-	<property>
-		<name>xasecure.audit.hdfs.config.destination.open.retry.interval.seconds</name>
-		<value>60</value>
-	</property>
-
-	<property>
-		<name>xasecure.audit.hdfs.config.local.buffer.directory</name>
-		<value>/var/log/storm/audit</value>
-	</property>	
-
-	<property>
-		<name>xasecure.audit.hdfs.config.local.buffer.file</name>
-		<value>%time:yyyyMMdd-HHmm.ss%.log</value>
-	</property>	
-
-	<property>
-		<name>xasecure.audit.hdfs.config.local.buffer.file.buffer.size.bytes</name>
-		<value>8192</value>
-	</property>	
-
-	<property>
-		<name>xasecure.audit.hdfs.config.local.buffer.flush.interval.seconds</name>
-		<value>60</value>
-	</property>	
-
-	<property>
-		<name>xasecure.audit.hdfs.config.local.buffer.rollover.interval.seconds</name>
-		<value>600</value>
-	</property>	
-
-	<property>
-		<name>xasecure.audit.hdfs.config.local.archive.directory</name>
-		<value>/var/log/storm/audit/archive</value>
-	</property>	
-
-	<property>
-		<name>xasecure.audit.hdfs.config.local.archive.max.file.count</name>
-		<value>10</value>
-	</property>	
-	
-	<!-- Audit to HDFS on Azure Datastore (WASB) requires v3 style settings.  Comment the above and uncomment only the
-	following to audit to Azure Blob Datastore via hdfs' WASB schema.
-
-	NOTE: If you specify one audit destination in v3 style then other destinations, if any, must also be specified in v3 style
-	====
-
-	<property>
-		<name>xasecure.audit.destination.hdfs</name>
-		<value>enabled</value>
-	</property>
-
-	<property>
-		<name>xasecure.audit.destination.hdfs.dir</name>
-		<value>wasb://ranger-audit1@youraccount.blob.core.windows.net</value>
-	</property>
-
-	the following 3 correspond to the properties with similar name in core-site.xml, i.e.
-	- fs.azure.account.key.youraccount.blob.core.windows.net => xasecure.audit.destination.hdfs.config.fs.azure.account.key.youraccount.blob.core.windows.net and
-	- fs.azure.account.keyprovider.youraccount.blob.core.windows.net => xasecure.audit.destination.hdfs.config.fs.azure.account.keyprovider.youraccount.blob.core.windows.net,
-	- fs.azure.shellkeyprovider.script => xasecure.audit.destination.hdfs.config.fs.azure.shellkeyprovider.script,
-
-	<property>
-		<name>xasecure.audit.destination.hdfs.config.fs.azure.account.key.youraccount.blob.core.windows.net</name>
-		<value>YOUR ENCRYPTED ACCESS KEY</value>
-	</property>
-
-	<property>
-		<name>xasecure.audit.destination.hdfs.config.fs.azure.account.keyprovider.youraccount.blob.core.windows.net</name>
-		<value>org.apache.hadoop.fs.azure.ShellDecryptionKeyProvider</value>
-	</property>
-
-	<property>
-		<name>xasecure.audit.destination.hdfs.config.fs.azure.shellkeyprovider.script</name>
-		<value>/usr/lib/python2.7/dist-packages/hdinsight_common/decrypt.sh</value>
-	</property>
-	-->
-
-	<!-- Log4j audit provider configuration -->
-	<property>
-		<name>xasecure.audit.log4j.is.enabled</name>
-		<value>false</value>
-	</property>	
-
-	<property>
-		<name>xasecure.audit.log4j.is.async</name>
-		<value>false</value>
-	</property>	
-	
-	<property>
-		<name>xasecure.audit.log4j.async.max.queue.size</name>
-		<value>10240</value>
-	</property>	
-
-	<property>
-		<name>xasecure.audit.log4j.async.max.flush.interval.ms</name>
-		<value>30000</value>
-	</property>	
-	
-	<!-- Kafka audit provider configuration -->
-	<property>
-		<name>xasecure.audit.kafka.is.enabled</name>
-		<value>false</value>
-	</property>	
-
-	<property>
-		<name>xasecure.audit.kafka.async.max.queue.size</name>
-		<value>1</value>
-	</property>	
-
-	<property>
-		<name>xasecure.audit.kafka.async.max.flush.interval.ms</name>
-		<value>1000</value>
-	</property>	
-	
-	<property>
-		<name>xasecure.audit.kafka.broker_list</name>
-		<value>localhost:9092</value>
-	</property>	
-
-	<property>
-		<name>xasecure.audit.kafka.topic_name</name>
-		<value>ranger_audits</value>
-	</property>	
-	
-	<!-- Ranger audit provider configuration -->
-	<property>
-		<name>xasecure.audit.solr.is.enabled</name>
-		<value>false</value>
-	</property>
-	
-	<property>
-		<name>xasecure.audit.solr.async.max.queue.size</name>
-		<value>1</value>
-	</property>	
-
-	<property>
-		<name>xasecure.audit.solr.async.max.flush.interval.ms</name>
-		<value>1000</value>
-	</property>	
-	
-	<property>
-		<name>xasecure.audit.solr.solr_url</name>
-		<value>http://localhost:6083/solr/ranger_audits</value>
-	</property>	
-
-</configuration>
diff --git a/storm-agent/conf/ranger-storm-security-changes.cfg b/storm-agent/conf/ranger-storm-security-changes.cfg
deleted file mode 100644
index 1929b7ef3..000000000
--- a/storm-agent/conf/ranger-storm-security-changes.cfg
+++ /dev/null
@@ -1,28 +0,0 @@
-# Licensed to the Apache Software Foundation (ASF) under one or more
-# contributor license agreements.  See the NOTICE file distributed with
-# this work for additional information regarding copyright ownership.
-# The ASF licenses this file to You under the Apache License, Version 2.0
-# (the "License"); you may not use this file except in compliance with
-# the License.  You may obtain a copy of the License at
-#
-#     http://www.apache.org/licenses/LICENSE-2.0
-#
-# Unless required by applicable law or agreed to in writing, software
-# distributed under the License is distributed on an "AS IS" BASIS,
-# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-# See the License for the specific language governing permissions and
-# limitations under the License.
-#
-# Change the original policy parameter to work with policy manager based.
-# 
-#
-ranger.plugin.storm.service.name %REPOSITORY_NAME% mod create-if-not-exists
-
-ranger.plugin.storm.policy.source.impl org.apache.ranger.admin.client.RangerAdminRESTClient mod create-if-not-exists
-
-ranger.plugin.storm.policy.rest.url                %POLICY_MGR_URL%                          mod create-if-not-exists
-ranger.plugin.storm.policy.rest.ssl.config.file    %COMPONENT_INSTALL_DIR_NAME%/conf/ranger-policymgr-ssl.xml  mod create-if-not-exists
-ranger.plugin.storm.policy.pollIntervalMs          30000                                     mod create-if-not-exists
-ranger.plugin.storm.policy.cache.dir               %POLICY_CACHE_FILE_PATH%                  mod create-if-not-exists
-ranger.plugin.storm.policy.rest.client.connection.timeoutMs    120000					     mod create-if-not-exists
-ranger.plugin.storm.policy.rest.client.read.timeoutMs	   	   30000					  	 mod create-if-not-exists
\ No newline at end of file
diff --git a/storm-agent/conf/ranger-storm-security.xml b/storm-agent/conf/ranger-storm-security.xml
deleted file mode 100644
index e9e7ea936..000000000
--- a/storm-agent/conf/ranger-storm-security.xml
+++ /dev/null
@@ -1,83 +0,0 @@
-<?xml version="1.0"?>
-<!--
-  Licensed to the Apache Software Foundation (ASF) under one or more
-  contributor license agreements.  See the NOTICE file distributed with
-  this work for additional information regarding copyright ownership.
-  The ASF licenses this file to You under the Apache License, Version 2.0
-  (the "License"); you may not use this file except in compliance with
-  the License.  You may obtain a copy of the License at
-
-      http://www.apache.org/licenses/LICENSE-2.0
-
-  Unless required by applicable law or agreed to in writing, software
-  distributed under the License is distributed on an "AS IS" BASIS,
-  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-  See the License for the specific language governing permissions and
-  limitations under the License.
--->
-<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
-<configuration xmlns:xi="http://www.w3.org/2001/XInclude">
-	<property>
-		<name>ranger.plugin.storm.service.name</name>
-		<value>stormdev</value>
-		<description>
-			Name of the Ranger service containing policies for this YARN instance
-		</description>
-	</property>
-
-	<property>
-		<name>ranger.plugin.storm.policy.source.impl</name>
-		<value>org.apache.ranger.admin.client.RangerAdminRESTClient</value>
-		<description>
-			Class to retrieve policies from the source
-		</description>
-	</property>
-
-	<property>
-		<name>ranger.plugin.storm.policy.rest.url</name>
-		<value>http://policymanagerhost:port</value>
-		<description>
-			URL to Ranger Admin
-		</description>
-	</property>
-
-	<property>
-		<name>ranger.plugin.storm.policy.rest.ssl.config.file</name>
-		<value>/etc/storm/conf/ranger-policymgr-ssl.xml</value>
-		<description>
-			Path to the file containing SSL details to contact Ranger Admin
-		</description>
-	</property>
-
-	<property>
-		<name>ranger.plugin.storm.policy.pollIntervalMs</name>
-		<value>30000</value>
-		<description>
-			How often to poll for changes in policies?
-		</description>
-	</property>
-
-	<property>
-		<name>ranger.plugin.storm.policy.cache.dir</name>
-		<value>/etc/ranger/stormdev/policycache</value>
-		<description>
-			Directory where Ranger policies are cached after successful retrieval from the source
-		</description>
-	</property>
-
-	<property>
-		<name>ranger.plugin.storm.policy.rest.client.connection.timeoutMs</name>
-		<value>120000</value>
-		<description>
-			RangerRestClient Connection Timeout in Milli Seconds
-		</description>
-	</property>
-
-	<property>
-		<name>ranger.plugin.storm.policy.rest.client.read.timeoutMs</name>
-		<value>30000</value>
-		<description>
-			RangerRestClient read Timeout in Milli Seconds
-		</description>
-	</property>	
-</configuration>
diff --git a/storm-agent/pom.xml b/storm-agent/pom.xml
deleted file mode 100644
index 0e4b9404a..000000000
--- a/storm-agent/pom.xml
+++ /dev/null
@@ -1,134 +0,0 @@
-<?xml version="1.0" encoding="UTF-8"?>
-<!--
-  Licensed to the Apache Software Foundation (ASF) under one or more
-  contributor license agreements.  See the NOTICE file distributed with
-  this work for additional information regarding copyright ownership.
-  The ASF licenses this file to You under the Apache License, Version 2.0
-  (the "License"); you may not use this file except in compliance with
-  the License.  You may obtain a copy of the License at
-
-      http://www.apache.org/licenses/LICENSE-2.0
-
-  Unless required by applicable law or agreed to in writing, software
-  distributed under the License is distributed on an "AS IS" BASIS,
-  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-  See the License for the specific language governing permissions and
-  limitations under the License.
--->
-<project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd">
-    <modelVersion>4.0.0</modelVersion>
-    <artifactId>ranger-storm-plugin</artifactId>
-    <name>Storm Security Plugin</name>
-    <description>Storm Security Plugins</description>
-    <packaging>jar</packaging>
-    <properties>
-        <project.build.sourceEncoding>UTF-8</project.build.sourceEncoding>
-    </properties>
-    <parent>
-        <groupId>org.apache.ranger</groupId>
-        <artifactId>ranger</artifactId>
-        <version>2.2.0</version>
-        <relativePath>..</relativePath>
-    </parent>
-    <dependencies>
-        <dependency>
-            <groupId>org.apache.storm</groupId>
-            <artifactId>storm-core</artifactId>
-            <version>${storm.version}</version>
-            <exclusions>
-                <exclusion>
-                    <groupId>org.slf4j</groupId>
-                    <artifactId>log4j-over-slf4j</artifactId>
-                </exclusion>
-            </exclusions>
-        </dependency>
-        <dependency>
-            <groupId>org.apache.ranger</groupId>
-            <artifactId>ranger-plugins-common</artifactId>
-            <version>${project.version}</version>
-            <exclusions>
-                <exclusion>
-                    <groupId>org.slf4j</groupId>
-                    <artifactId>slf4j-log4j12</artifactId>
-                </exclusion>
-                <exclusion>
-                    <groupId>org.apache.hadoop</groupId>
-                    <artifactId>hadoop-common</artifactId>
-                </exclusion>
-            </exclusions>
-        </dependency>
-        <dependency>
-            <groupId>org.apache.ranger</groupId>
-            <artifactId>ranger-plugins-audit</artifactId>
-            <version>${project.version}</version>
-            <exclusions>
-                <exclusion>
-                    <groupId>org.slf4j</groupId>
-                    <artifactId>slf4j-log4j12</artifactId>
-                </exclusion>
-                <exclusion>
-                    <groupId>org.apache.hadoop</groupId>
-                    <artifactId>hadoop-common</artifactId>
-                </exclusion>
-            </exclusions>
-        </dependency>
-        <dependency>
-            <groupId>org.apache.ranger</groupId>
-            <artifactId>credentialbuilder</artifactId>
-            <version>${project.version}</version>
-            <exclusions>
-                <exclusion>
-                    <groupId>org.slf4j</groupId>
-                    <artifactId>slf4j-log4j12</artifactId>
-                </exclusion>
-            </exclusions>
-        </dependency>
-        <dependency>
-            <groupId>org.apache.hadoop</groupId>
-            <artifactId>hadoop-hdfs</artifactId>
-            <version>${hadoop.version}</version>
-        </dependency>
-        <dependency>
-            <groupId>org.apache.hadoop</groupId>
-            <artifactId>hadoop-common</artifactId>
-            <version>${hadoop.version}</version>
-        </dependency>
-        <dependency>
-    		<groupId>org.apache.httpcomponents</groupId>
-    		<artifactId>httpcore</artifactId>
-    		<version>${httpcomponents.httpcore.version}</version>
-	</dependency>
-	<dependency>
-            <groupId>commons-codec</groupId>
-            <artifactId>commons-codec</artifactId>
-            <version>${commons.codec.version}</version>
-	</dependency>
-        <dependency>
-            <groupId>junit</groupId>
-            <artifactId>junit</artifactId>
-        </dependency>
-    </dependencies>
-    <build>
-        <testResources>
-           <testResource>
-                <directory>src/test/resources</directory>
-                <includes>
-                    <include>**/*</include>
-                </includes>
-                <filtering>true</filtering>
-            </testResource>
-        </testResources>
-        <plugins>
-            <plugin>
-                <groupId>org.apache.maven.plugins</groupId>
-                <artifactId>maven-surefire-plugin</artifactId>
-                <inherited>true</inherited>
-                <configuration>
-                    <systemPropertyVariables>
-                        <storm.home>${basedir}/target</storm.home>
-                    </systemPropertyVariables>
-                </configuration>
-            </plugin>
-        </plugins>
-    </build>
-</project>
diff --git a/storm-agent/scripts/install.properties b/storm-agent/scripts/install.properties
deleted file mode 100644
index 109300f33..000000000
--- a/storm-agent/scripts/install.properties
+++ /dev/null
@@ -1,164 +0,0 @@
-# Licensed to the Apache Software Foundation (ASF) under one or more
-# contributor license agreements.  See the NOTICE file distributed with
-# this work for additional information regarding copyright ownership.
-# The ASF licenses this file to You under the Apache License, Version 2.0
-# (the "License"); you may not use this file except in compliance with
-# the License.  You may obtain a copy of the License at
-#
-#     http://www.apache.org/licenses/LICENSE-2.0
-#
-# Unless required by applicable law or agreed to in writing, software
-# distributed under the License is distributed on an "AS IS" BASIS,
-# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-# See the License for the specific language governing permissions and
-# limitations under the License.
-
-#
-# Location of Policy Manager URL  
-#
-# Example:
-# POLICY_MGR_URL=http://policymanager.xasecure.net:6080
-#
-POLICY_MGR_URL=
-
-#
-# This is the repository name created within policy manager
-#
-# Example:
-# REPOSITORY_NAME=stormdev
-#
-REPOSITORY_NAME=
-
-#
-# Apache Storm installation path
-#
-COMPONENT_INSTALL_DIR_NAME=storm
-
-# AUDIT configuration with V3 properties
-
-# Enable audit logs to Solr
-#Example
-#XAAUDIT.SOLR.ENABLE=true
-#XAAUDIT.SOLR.URL=http://localhost:6083/solr/ranger_audits
-#XAAUDIT.SOLR.ZOOKEEPER=
-#XAAUDIT.SOLR.FILE_SPOOL_DIR=/var/log/storm/audit/solr/spool
-
-XAAUDIT.SOLR.ENABLE=false
-XAAUDIT.SOLR.URL=NONE
-XAAUDIT.SOLR.USER=NONE
-XAAUDIT.SOLR.PASSWORD=NONE
-XAAUDIT.SOLR.ZOOKEEPER=NONE
-XAAUDIT.SOLR.FILE_SPOOL_DIR=/var/log/storm/audit/solr/spool
-
-# Enable audit logs to ElasticSearch
-#Example
-#XAAUDIT.ELASTICSEARCH.ENABLE=true
-#XAAUDIT.ELASTICSEARCH.URL=localhost
-#XAAUDIT.ELASTICSEARCH.INDEX=audit
-
-XAAUDIT.ELASTICSEARCH.ENABLE=false
-XAAUDIT.ELASTICSEARCH.URL=NONE
-XAAUDIT.ELASTICSEARCH.USER=NONE
-XAAUDIT.ELASTICSEARCH.PASSWORD=NONE
-XAAUDIT.ELASTICSEARCH.INDEX=NONE
-XAAUDIT.ELASTICSEARCH.PORT=NONE
-XAAUDIT.ELASTICSEARCH.PROTOCOL=NONE
-
-# Enable audit logs to HDFS
-#Example
-#XAAUDIT.HDFS.ENABLE=true
-#XAAUDIT.HDFS.HDFS_DIR=hdfs://node-1.example.com:8020/ranger/audit
-#  If using Azure Blob Storage
-#XAAUDIT.HDFS.HDFS_DIR=wasb[s]://<containername>@<accountname>.blob.core.windows.net/<path>
-#XAAUDIT.HDFS.HDFS_DIR=wasb://ranger_audit_container@my-azure-account.blob.core.windows.net/ranger/audit
-#XAAUDIT.HDFS.FILE_SPOOL_DIR=/var/log/storm/audit/hdfs/spool
-
-XAAUDIT.HDFS.ENABLE=false
-XAAUDIT.HDFS.HDFS_DIR=hdfs://__REPLACE__NAME_NODE_HOST:8020/ranger/audit
-XAAUDIT.HDFS.FILE_SPOOL_DIR=/var/log/storm/audit/hdfs/spool
-
-# Following additional propertis are needed When auditing to Azure Blob Storage via HDFS
-# Get these values from your /etc/hadoop/conf/core-site.xml
-#XAAUDIT.HDFS.HDFS_DIR=wasb[s]://<containername>@<accountname>.blob.core.windows.net/<path>
-XAAUDIT.HDFS.AZURE_ACCOUNTNAME=__REPLACE_AZURE_ACCOUNT_NAME
-XAAUDIT.HDFS.AZURE_ACCOUNTKEY=__REPLACE_AZURE_ACCOUNT_KEY
-XAAUDIT.HDFS.AZURE_SHELL_KEY_PROVIDER=__REPLACE_AZURE_SHELL_KEY_PROVIDER
-XAAUDIT.HDFS.AZURE_ACCOUNTKEY_PROVIDER=__REPLACE_AZURE_ACCOUNT_KEY_PROVIDER
-
-#Log4j Audit Provider
-XAAUDIT.LOG4J.ENABLE=false
-XAAUDIT.LOG4J.IS_ASYNC=false
-XAAUDIT.LOG4J.ASYNC.MAX.QUEUE.SIZE=10240
-XAAUDIT.LOG4J.ASYNC.MAX.FLUSH.INTERVAL.MS=30000
-XAAUDIT.LOG4J.DESTINATION.LOG4J=true
-XAAUDIT.LOG4J.DESTINATION.LOG4J.LOGGER=xaaudit
-
-# End of V3 properties
-
-
-#
-#  Audit to HDFS Configuration
-#
-# If XAAUDIT.HDFS.IS_ENABLED is set to true, please replace tokens
-# that start with __REPLACE__ with appropriate values
-#  XAAUDIT.HDFS.IS_ENABLED=true
-#  XAAUDIT.HDFS.DESTINATION_DIRECTORY=hdfs://__REPLACE__NAME_NODE_HOST:8020/ranger/audit/%app-type%/%time:yyyyMMdd%
-#  XAAUDIT.HDFS.LOCAL_BUFFER_DIRECTORY=__REPLACE__LOG_DIR/storm/audit
-#  XAAUDIT.HDFS.LOCAL_ARCHIVE_DIRECTORY=__REPLACE__LOG_DIR/storm/audit/archive
-#
-# Example:
-#  XAAUDIT.HDFS.IS_ENABLED=true
-#  XAAUDIT.HDFS.DESTINATION_DIRECTORY=hdfs://namenode.example.com:8020/ranger/audit/%app-type%/%time:yyyyMMdd%
-#  XAAUDIT.HDFS.LOCAL_BUFFER_DIRECTORY=/var/log/storm/audit
-#  XAAUDIT.HDFS.LOCAL_ARCHIVE_DIRECTORY=/var/log/storm/audit/archive
-#
-XAAUDIT.HDFS.IS_ENABLED=false
-XAAUDIT.HDFS.DESTINATION_DIRECTORY=hdfs://__REPLACE__NAME_NODE_HOST:8020/ranger/audit/%app-type%/%time:yyyyMMdd%
-XAAUDIT.HDFS.LOCAL_BUFFER_DIRECTORY=__REPLACE__LOG_DIR/storm/audit
-XAAUDIT.HDFS.LOCAL_ARCHIVE_DIRECTORY=__REPLACE__LOG_DIR/storm/audit/archive
-
-XAAUDIT.HDFS.DESTINTATION_FILE=%hostname%-audit.log
-XAAUDIT.HDFS.DESTINTATION_FLUSH_INTERVAL_SECONDS=900
-XAAUDIT.HDFS.DESTINTATION_ROLLOVER_INTERVAL_SECONDS=86400
-XAAUDIT.HDFS.DESTINTATION_OPEN_RETRY_INTERVAL_SECONDS=60
-XAAUDIT.HDFS.LOCAL_BUFFER_FILE=%time:yyyyMMdd-HHmm.ss%.log
-XAAUDIT.HDFS.LOCAL_BUFFER_FLUSH_INTERVAL_SECONDS=60
-XAAUDIT.HDFS.LOCAL_BUFFER_ROLLOVER_INTERVAL_SECONDS=600
-XAAUDIT.HDFS.LOCAL_ARCHIVE_MAX_FILE_COUNT=10
-
-#Solr Audit Provider
-XAAUDIT.SOLR.IS_ENABLED=false
-XAAUDIT.SOLR.MAX_QUEUE_SIZE=1
-XAAUDIT.SOLR.MAX_FLUSH_INTERVAL_MS=1000
-XAAUDIT.SOLR.SOLR_URL=http://localhost:6083/solr/ranger_audits
-
-# End of V2 properties
-
-#
-# SSL Client Certificate Information
-#
-# Example:
-# SSL_KEYSTORE_FILE_PATH=/etc/storm/conf/ranger-plugin-keystore.jks
-# SSL_KEYSTORE_PASSWORD=none
-# SSL_TRUSTSTORE_FILE_PATH=/etc/storm/conf/ranger-plugin-truststore.jks
-# SSL_TRUSTSTORE_PASSWORD=none
-#
-# You do not need use SSL between agent and security admin tool, please leave these sample value as it is.
-#
-SSL_KEYSTORE_FILE_PATH=/etc/storm/conf/ranger-plugin-keystore.jks
-SSL_KEYSTORE_PASSWORD=myKeyFilePassword
-SSL_TRUSTSTORE_FILE_PATH=/etc/storm/conf/ranger-plugin-truststore.jks
-SSL_TRUSTSTORE_PASSWORD=changeit
-
-#
-# Custom component user
-# CUSTOM_COMPONENT_USER=<custom-user>
-# keep blank if component user is default
-CUSTOM_USER=storm
-
-
-#
-# Custom component group
-# CUSTOM_COMPONENT_GROUP=<custom-group>
-# keep blank if component group is default
-CUSTOM_GROUP=hadoop
diff --git a/storm-agent/scripts/install.sh b/storm-agent/scripts/install.sh
deleted file mode 100644
index 4de934d00..000000000
--- a/storm-agent/scripts/install.sh
+++ /dev/null
@@ -1,307 +0,0 @@
-#!/bin/bash
-
-# Licensed to the Apache Software Foundation (ASF) under one or more
-# contributor license agreements.  See the NOTICE file distributed with
-# this work for additional information regarding copyright ownership.
-# The ASF licenses this file to You under the Apache License, Version 2.0
-# (the "License"); you may not use this file except in compliance with
-# the License.  You may obtain a copy of the License at
-#
-#     http://www.apache.org/licenses/LICENSE-2.0
-#
-# Unless required by applicable law or agreed to in writing, software
-# distributed under the License is distributed on an "AS IS" BASIS,
-# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-# See the License for the specific language governing permissions and
-# limitations under the License.
-
-
-create_jceks()
-{
-	alias=$1
-	pass=$2
-	jceksFile=$3
-	
-	java -cp "${install_dir}/cred/lib/*:${install_dir}/installer/lib/*" org.apache.ranger.credentialapi.buildks create ${alias} -value ${pass} -provider jceks://file${jceksFile}
-	if [ $? -ne 0 ]
-	then
-		echo "ERROR: Unable to create/update credential file [${jceksFile}] for alias [${alias}]"
-		exit 1
-	fi
-}
-
-#Update Properties to File
-#$1 -> propertyName $2 -> newPropertyValue $3 -> fileName
-updatePropertyToFile(){
-	sed -i 's@^'$1'=[^ ]*$@'$1'='$2'@g' $3
-	#validate=`sed -i 's/^'$1'=[^ ]*$/'$1'='$2'/g' $3`	#for validation
-	validate=$(sed '/^\#/d' $3 | grep "^$1"  | tail -n 1 | cut -d "=" -f2-) # for validation
-	#echo 'V1:'$validate
-	if test -z "$validate" ; then echo "[E] '$1' not found in $3 file while Updating....!!"; exit 1; fi
-	echo "[I] File $3 Updated successfully : {'$1'}"
-}
-
-storm_dir=/usr/lib/storm
-storm_lib_dir=${storm_dir}/lib
-storm_conf_dir=/etc/storm/conf
-storm_bin_dir=${storm_dir}/bin
-
-CONFIG_FILE_OWNER=storm:storm
-
-storm_srv_conf_dir=${storm_conf_dir}
-storm_cli_conf_dir="${storm_conf_dir}"
-
-install_dir=`dirname $0`
-
-[ "${install_dir}" = "." ] && install_dir=`pwd`
-
-
-#verify sql-connector path is valid
-SQL_CONNECTOR_JAR=`grep '^SQL_CONNECTOR_JAR'  ${install_dir}/install.properties | awk -F= '{ print $2 }'`
-echo "[I] Checking SQL CONNECTOR FILE : $SQL_CONNECTOR_JAR"
-if test -f "$SQL_CONNECTOR_JAR"; then
-	echo "[I] SQL CONNECTOR FILE : $SQL_CONNECTOR_JAR file found"
-else
-	echo "[E] SQL CONNECTOR FILE : $SQL_CONNECTOR_JAR not found, aborting installation"
-  exit 1
-fi
-#copying sql connector jar file to lib directory
-cp $SQL_CONNECTOR_JAR ${install_dir}/lib
-
-#echo "Current Install Directory: [${install_dir}]"
-
-
-#
-# --- Backup current configuration for backup - START
-#
-
-COMPONENT_NAME=storm
-
-XASECURE_VERSION=`cat ${install_dir}/version`
-
-CFG_DIR=${storm_conf_dir}
-XASECURE_ROOT=/etc/xasecure/${COMPONENT_NAME}
-BACKUP_TYPE=pre
-CUR_VERSION_FILE=${XASECURE_ROOT}/.current_version
-CUR_CFG_DIR_FILE=${XASECURE_ROOT}/.config_dir
-PRE_INSTALL_CONFIG=${XASECURE_ROOT}/${BACKUP_TYPE}-${XASECURE_VERSION}
-
-if [ ! -d ${XASECURE_ROOT} ]
-then
-	mkdir -p ${XASECURE_ROOT}
-fi
-
-backup_dt=`date '+%Y%m%d%H%M%S'`
-
-if [ -d "${PRE_INSTALL_CONFIG}" ]
-then
-	PRE_INSTALL_CONFIG="${PRE_INSTALL_CONFIG}.${backup_dt}"
-fi
-
-if [ -d ${CFG_DIR} ]
-then
-	( cd ${CFG_DIR} ; find . -print | cpio -pdm ${PRE_INSTALL_CONFIG} )
-	[ -f ${CUR_VERSION_FILE} ] && mv ${CUR_VERSION_FILE} ${CUR_VERSION_FILE}-${backup_dt}
-	echo ${XASECURE_VERSION} > ${CUR_VERSION_FILE}
-	echo ${CFG_DIR} > ${CUR_CFG_DIR_FILE}
-else
-	echo "+ mkdir -p ${CFG_DIR} ..."
-	mkdir -p ${CFG_DIR}
-fi
-
-cp -f ${install_dir}/uninstall.sh ${XASECURE_ROOT}/
-
-#
-# --- Backup current configuration for backup  - END
-#
-
-
-dt=`date '+%Y%m%d%H%M%S'`
-for f in ${install_dir}/conf/*
-do
-	if [ -f ${f} ]
-	then
-		fn=`basename $f`
-		if [ ! -f ${storm_conf_dir}/${fn} ]
-		then
-			echo "+cp ${f} ${storm_conf_dir}/${fn}"
-			cp ${f} ${storm_conf_dir}/${fn}
-		else
-			echo "WARN: ${fn} already exists in the ${storm_conf_dir} - Using existing configuration ${fn}"
-		fi
-	fi
-done
-
-
-if [ ! -d ${storm_lib_dir} ]
-then
-	echo "+mkdir -p ${storm_lib_dir}"
-	mkdir -p ${storm_lib_dir}
-fi
-
-for f in ${install_dir}/dist/*.jar ${install_dir}/lib/*.jar
-do
-	if [ -f ${f} ]
-	then
-		fn=`basename $f`
-		echo "+cp ${f} ${storm_lib_dir}/${fn}"
-		cp ${f} ${storm_lib_dir}/${fn}
-	fi
-done
-
-#
-# Copy the SSL parameters
-#
-
-CredFile=`grep '^CREDENTIAL_PROVIDER_FILE' ${install_dir}/install.properties | awk -F= '{ print $2 }'`
-
-if ! [ `echo ${CredFile} | grep '^/.*'` ]
-then
-  echo "ERROR:Please enter the Credential File Store with proper file path"
-  exit 1
-fi
-pardir=`dirname ${CredFile}`
-
-if [ ! -d ${pardir} ]
-then
-        mkdir -p ${pardir}
-        chmod go+rx ${pardir}
-fi
-
-#
-# Generate Credential Provider file and Credential for SSL KEYSTORE AND TRUSTSTORE
-#
-sslkeystoreAlias="sslKeyStore"
-
-sslkeystoreCred=`grep '^SSL_KEYSTORE_PASSWORD' ${install_dir}/install.properties | awk -F= '{ print $2 }'`
-
-create_jceks ${sslkeystoreAlias} ${sslkeystoreCred} ${CredFile}
-
-
-ssltruststoreAlias="sslTrustStore"
-
-ssltruststoreCred=`grep '^SSL_TRUSTSTORE_PASSWORD' ${install_dir}/install.properties | awk -F= '{ print $2 }'`
-
-create_jceks ${ssltruststoreAlias} ${ssltruststoreCred} ${CredFile}
-
-chown ${CONFIG_FILE_OWNER} ${CredFile} 
-
-PROP_ARGS="-p  ${install_dir}/install.properties"
-
-for f in ${install_dir}/installer/conf/*-changes.cfg
-do
-        if [ -f ${f} ]
-	then
-                fn=`basename $f`
-                orgfn=`echo $fn | sed -e 's:-changes.cfg:.xml:'`
-                fullpathorgfn="${storm_conf_dir}/${orgfn}"
-                if [ ! -f ${fullpathorgfn} ]
-                then
-                        echo "ERROR: Unable to find ${fullpathorgfn}"
-                        exit 1
-                fi
-                archivefn="${storm_conf_dir}/.${orgfn}.${dt}"
-                newfn="${storm_conf_dir}/.${orgfn}-new.${dt}"
-                cp ${fullpathorgfn} ${archivefn}
-                if [ $? -eq 0 ]
-                then
-                	cp="${install_dir}/installer/lib/*:${install_dir}/cred/lib/*:"
-                        java -cp "${cp}" org.apache.ranger.utils.install.XmlConfigChanger -i ${archivefn} -o ${newfn} -c ${f} ${PROP_ARGS}
-                        if [ $? -eq 0 ]
-                        then
-                                diff -w ${newfn} ${fullpathorgfn} > /dev/null 2>&1 
-                                if [ $? -ne 0 ]
-                                then
-	                        		#echo "Changing config file:  ${fullpathorgfn} with following changes:"
-	                                #echo "==============================================================="
-	                                #diff -w ${newfn} ${fullpathorgfn}
-	                                #echo "==============================================================="
-	                                echo "NOTE: Current config file: ${fullpathorgfn} is being saved as ${archivefn}"
-	                                #echo "==============================================================="
-	                                cp ${newfn} ${fullpathorgfn}
-	                            fi
-                        else
-                                echo "ERROR: Unable to make changes to config. file: ${fullpathorgfn}"
-                                echo "exiting ...."
-                                exit 1
-                        fi
-                else
-                        echo "ERROR: Unable to save config. file: ${fullpathorgfn}  to ${archivefn}"
-                        echo "exiting ...."
-                        exit 1
-                fi
-        fi
-done
-
-chmod go-rwx ${storm_conf_dir}/xasecure-policymgr-ssl.xml
-chown ${CONFIG_FILE_OWNER} ${storm_conf_dir}/xasecure-policymgr-ssl.xml
-
-#
-# Adding authorizer to storm.yaml configuration file ...
-#
-STORM_DIR=/etc/storm
-STORM_CONFIG_FILE=storm.yaml
-STORM_BIN_FILE=/usr/bin/storm
-
-dt=`date '+%Y%m%d%H%M%S'`
-CONFIG_FILE=${STORM_DIR}/${STORM_CONFIG_FILE}
-ARCHIVE_FILE=${STORM_DIR}/.${STORM_CONFIG_FILE}.${dt}
-STORM_BIN_ARCHIVE_FILE=/usr/bin/.storm.${dt}
-
-cp ${CONFIG_FILE} ${ARCHIVE_FILE}
-
-awk -F: 'BEGIN {
-	configured = 0 ;
-}
-{ 
-	if ($1 == "nimbus.authorizer") {
-		if ($2 ~ /^[ \t]*"org.apache.ranger.authorization.storm.authorizer.RangerStormAuthorizer"[ \t]*$/) {
-			configured = 1 ;
-			printf("%s\n",$0) ;
-		}
-		else {
-			printf("#%s\n",$0);
-			printf("nimbus.authorizer: \"org.apache.ranger.authorization.storm.authorizer.RangerStormAuthorizer\"\n") ;
-			configured = 1 ;
-		}
-	}
-	else {
-		printf("%s\n",$0) ;
-	}
-}
-END {
-	if (configured == 0) {
-		printf("nimbus.authorizer: \"org.apache.ranger.authorization.storm.authorizer.RangerStormAuthorizer\"\n") ;
-	}
-}' ${ARCHIVE_FILE} > ${ARCHIVE_FILE}.new 
-
-if [ ! -z ${ARCHIVE_FILE}.new ] 
-then
-	cat ${ARCHIVE_FILE}.new > ${CONFIG_FILE}
-	rm -f ${ARCHIVE_FILE}.new
-else
-	echo "ERROR: ${ARCHIVE_FILE}.new file has not created successfully."
-	exit 1
-fi
-
-#
-# Modify the CLASSPATH of the Storm Servers (ui, nimbus) ....
-#
-grep 'ret.extend(\["/etc/storm/conf"' ${STORM_BIN_FILE} > /dev/null
-if [ $? -ne 0 ]
-then
-        temp=/tmp/storm.tmp.$$
-        cat ${STORM_BIN_FILE} | sed -e '/ret = get_jars_full(STORM_DIR)/ a\
-    ret.extend(["/etc/storm/conf","/usr/lib/storm/lib/*"])' > ${temp}
-        if [ ! -z ${temp} ]
-        then
-				cp ${STORM_BIN_FILE} ${STORM_BIN_ARCHIVE_FILE}
-                cat ${temp} > ${STORM_BIN_FILE}
-		else
-			echo "ERROR: ${temp} file has not been created successfully."
-			exit 1
-        fi
-fi
-
-
-exit 0
diff --git a/storm-agent/scripts/uninstall.sh b/storm-agent/scripts/uninstall.sh
deleted file mode 100644
index 5ba2e18a6..000000000
--- a/storm-agent/scripts/uninstall.sh
+++ /dev/null
@@ -1,65 +0,0 @@
-#!/bin/bash
-
-# Licensed to the Apache Software Foundation (ASF) under one or more
-# contributor license agreements.  See the NOTICE file distributed with
-# this work for additional information regarding copyright ownership.
-# The ASF licenses this file to You under the Apache License, Version 2.0
-# (the "License"); you may not use this file except in compliance with
-# the License.  You may obtain a copy of the License at
-#
-#     http://www.apache.org/licenses/LICENSE-2.0
-#
-# Unless required by applicable law or agreed to in writing, software
-# distributed under the License is distributed on an "AS IS" BASIS,
-# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-# See the License for the specific language governing permissions and
-# limitations under the License.
-
-#
-# Replacing authorizer to storm.yaml configuration file ...
-#
-STORM_DIR=/etc/storm
-STORM_CONFIG_FILE=storm.yaml
-
-dt=`date '+%Y%m%d%H%M%S'`
-CONFIG_FILE=${STORM_DIR}/${STORM_CONFIG_FILE}
-ARCHIVE_FILE=${STORM_DIR}/.${STORM_CONFIG_FILE}.${dt}
-
-cp ${CONFIG_FILE} ${ARCHIVE_FILE}
-
-awk -F: 'BEGIN {
-	configured = 0 ;
-}
-{ 
-	if ($1 == "nimbus.authorizer") {
-		if ($2 ~ /^[ \t]*"org.apache.storm.security.auth.authorizer.SimpleACLAuthorizer"[ \t]*$/) {
-			configured = 1 ;
-			printf("%s\n",$0) ;
-		}
-		else {
-			printf("#%s\n",$0);
-			printf("nimbus.authorizer: \"org.apache.storm.security.auth.authorizer.SimpleACLAuthorizer\"\n") ;
-			configured = 1 ;
-		}
-	}
-	else {
-		printf("%s\n",$0) ;
-	}
-}
-END {
-	if (configured == 0) {
-		printf("nimbus.authorizer: \"org.apache.storm.security.auth.authorizer.SimpleACLAuthorizer\"\n") ;
-	}
-}' ${ARCHIVE_FILE} > ${ARCHIVE_FILE}.new 
-
-if [ ! -z ${ARCHIVE_FILE}.new ] 
-then
-	cat ${ARCHIVE_FILE}.new > ${CONFIG_FILE}
-	rm -f ${ARCHIVE_FILE}.new
-	echo "Apache Ranger Plugin has been uninstalled from Storm Service. Please restart Storm nimbus and ui services ..."
-else
-	echo "ERROR: ${ARCHIVE_FILE}.new file has not created successfully."
-	exit 1
-fi
-
-exit 0
diff --git a/storm-agent/src/main/java/org/apache/ranger/authorization/storm/StormRangerPlugin.java b/storm-agent/src/main/java/org/apache/ranger/authorization/storm/StormRangerPlugin.java
deleted file mode 100644
index bb0f88296..000000000
--- a/storm-agent/src/main/java/org/apache/ranger/authorization/storm/StormRangerPlugin.java
+++ /dev/null
@@ -1,131 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.ranger.authorization.storm;
-
-import java.util.Collections;
-import java.util.HashMap;
-import java.util.Map;
-import java.util.Set;
-
-import org.apache.commons.logging.Log;
-import org.apache.commons.logging.LogFactory;
-import org.apache.hadoop.security.authentication.util.KerberosName;
-import org.apache.ranger.authorization.storm.StormRangerPlugin.StormConstants.PluginConfiguration;
-import org.apache.ranger.authorization.storm.StormRangerPlugin.StormConstants.ResourceName;
-import org.apache.ranger.plugin.audit.RangerDefaultAuditHandler;
-import org.apache.ranger.plugin.policyengine.RangerAccessRequest;
-import org.apache.ranger.plugin.policyengine.RangerAccessRequestImpl;
-import org.apache.ranger.plugin.policyengine.RangerAccessResourceImpl;
-import org.apache.ranger.plugin.service.RangerBasePlugin;
-
-import com.google.common.collect.Sets;
-
-public class StormRangerPlugin extends RangerBasePlugin {
-	
-	private static final Log LOG = LogFactory.getLog(StormRangerPlugin.class);
-	boolean initialized = false;
-
-	private final Map<String,String> impliedAccessTypes;
-
-	public StormRangerPlugin() {
-		super(PluginConfiguration.ServiceType, PluginConfiguration.AuditApplicationType);
-
-		Map<String, String> impliedTypes = new HashMap<String, String>();
-		// In future this has to be part of Ranger Storm Service Def.
-		impliedTypes.put("getTopologyPageInfo","getTopologyInfo");
-		impliedTypes.put("getComponentPageInfo","getTopologyInfo");
-		impliedTypes.put("setWorkerProfiler","getTopologyInfo");
-		impliedTypes.put("getWorkerProfileActionExpiry","getTopologyInfo");
-		impliedTypes.put("getComponentPendingProfileActions","getTopologyInfo");
-		impliedTypes.put("startProfiling","getTopologyInfo");
-		impliedTypes.put("stopProfiling","getTopologyInfo");
-		impliedTypes.put("dumpProfile","getTopologyInfo");
-		impliedTypes.put("dumpJstack","getTopologyInfo");
-		impliedTypes.put("dumpHeap","getTopologyInfo");
-		impliedTypes.put("setLogConfig","getTopologyInfo");
-		impliedTypes.put("getLogConfig","getTopologyInfo");
-		impliedTypes.put("debug","getTopologyInfo");
-
-		this.impliedAccessTypes = Collections.unmodifiableMap(impliedTypes);
-	}
-
-	// this method isn't expected to be invoked often.  Per knox design this would be invoked ONCE right after the authorizer servlet is loaded
-	@Override
-	synchronized public void init() {
-		if (!initialized) {
-			// mandatory call to base plugin
-			super.init();
-			// One time call to register the audit hander with the policy engine.
-			super.setResultProcessor(new RangerDefaultAuditHandler(getConfig()));
-			// this needed to set things right in the nimbus process
-			if (KerberosName.getRules() == null) {
-				KerberosName.setRules("DEFAULT");
-			}
-
-			initialized = true;
-			LOG.info("StormRangerPlugin initialized!");
-		}
-	}
-
-	public RangerAccessRequest buildAccessRequest(String _user, String[] _groups, String _clientIp, String _topology, String _operation) {
-		
-		RangerAccessRequestImpl request = new RangerAccessRequestImpl();
-		request.setUser(_user);
-		if (_groups != null && _groups.length > 0) {
-			Set<String> groups = Sets.newHashSet(_groups);
-			request.setUserGroups(groups);
-		}
-
-		request.setAccessType(getAccessType(_operation));
-		request.setClientIPAddress(_clientIp);
-		request.setAction(_operation);
-		// build resource and connect stuff into request
-		RangerAccessResourceImpl resource = new RangerAccessResourceImpl();
-		resource.setValue(ResourceName.Topology, _topology);
-		request.setResource(resource);
-		
-		if (LOG.isDebugEnabled()) {
-			LOG.debug("Returning request: " + request.toString());
-		}
-		
-		return request;
-	}
-
-	private String getAccessType(String _operation) {
-		String ret = null;
-		ret = impliedAccessTypes.get(_operation);
-		if ( ret == null) {
-			ret = _operation;
-		}
-		return ret;
-	}
-
-	static public class StormConstants {
-		// Plugin parameters
-		static class PluginConfiguration {
-			static final String ServiceType = "storm";
-			static final String AuditApplicationType = "storm";
-		}
-		
-		// must match the corresponding string used in service definition file
-		static class ResourceName {
-			static final String Topology = "topology";
-		}
-	}
-
-}
diff --git a/storm-agent/src/main/java/org/apache/ranger/authorization/storm/authorizer/RangerStormAuthorizer.java b/storm-agent/src/main/java/org/apache/ranger/authorization/storm/authorizer/RangerStormAuthorizer.java
deleted file mode 100644
index ea367af44..000000000
--- a/storm-agent/src/main/java/org/apache/ranger/authorization/storm/authorizer/RangerStormAuthorizer.java
+++ /dev/null
@@ -1,186 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- * http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-
- package org.apache.ranger.authorization.storm.authorizer;
-
-import java.security.Principal;
-import java.util.Map;
-import java.util.Set;
-
-import org.apache.commons.logging.Log;
-import org.apache.hadoop.security.UserGroupInformation;
-import org.apache.ranger.audit.provider.MiscUtil;
-import org.apache.ranger.authorization.storm.StormRangerPlugin;
-import org.apache.ranger.authorization.utils.StringUtil;
-import org.apache.ranger.plugin.policyengine.RangerAccessRequest;
-import org.apache.ranger.plugin.policyengine.RangerAccessResult;
-import org.apache.ranger.plugin.util.RangerPerfTracer;
-import org.slf4j.Logger;
-import org.slf4j.LoggerFactory;
-
-import com.google.common.collect.Sets;
-
-import org.apache.storm.Config;
-import org.apache.storm.security.auth.IAuthorizer;
-import org.apache.storm.security.auth.ReqContext;
-
-
-public class RangerStormAuthorizer implements IAuthorizer {
-
-	private static final Logger LOG = LoggerFactory.getLogger(RangerStormAuthorizer.class);
-
-	private static final Log PERF_STORMAUTH_REQUEST_LOG = RangerPerfTracer.getPerfLogger("stormauth.request");
-
-	private static final String STORM_CLIENT_JASS_CONFIG_SECTION = "StormClient";
-
-	private static volatile StormRangerPlugin plugin = null;
-
-	static final Set<String> noAuthzOperations = Sets.newHashSet(new String[] { "getNimbusConf", "getClusterInfo" });
-
-	/**
-     * permit() method is invoked for each incoming Thrift request.
-     * @param aRequestContext request context includes info about
-     * @param aOperationName operation name
-     * @param aTopologyConfigMap configuration of targeted topology
-     * @return true if the request is authorized, false if reject
-     */
-	
-	@Override
-	public boolean permit(ReqContext aRequestContext, String aOperationName, Map aTopologyConfigMap) {
-		
-		boolean accessAllowed = false;
-		boolean isAuditEnabled = false;
-
-		String topologyName = null;
-
-		RangerPerfTracer perf = null;
-
-		try {
-
-			if(RangerPerfTracer.isPerfTraceEnabled(PERF_STORMAUTH_REQUEST_LOG)) {
-				perf = RangerPerfTracer.getPerfTracer(PERF_STORMAUTH_REQUEST_LOG, "RangerStormAuthorizer.permit()");
-			}
-
-			topologyName = (aTopologyConfigMap == null ? "" : (String)aTopologyConfigMap.get(Config.TOPOLOGY_NAME));
-	
-			if (LOG.isDebugEnabled()) {
-				LOG.debug("[req "+ aRequestContext.requestID()+ "] Access "
-		                + " from: [" + aRequestContext.remoteAddress() + "]"
-		                + " user: [" + aRequestContext.principal() + "],"
-		                + " op:   [" + aOperationName + "],"
-		                + "topology: [" + topologyName + "]");
-				
-				if (aTopologyConfigMap != null) {
-					for(Object keyObj : aTopologyConfigMap.keySet()) {
-						Object valObj = aTopologyConfigMap.get(keyObj);
-						LOG.debug("TOPOLOGY CONFIG MAP [" + keyObj + "] => [" + valObj + "]");
-					}
-				}
-				else {
-					LOG.debug("TOPOLOGY CONFIG MAP is passed as null.");
-				}
-			}
-
-			if(noAuthzOperations.contains(aOperationName)) {
-				accessAllowed = true;
-			} else if(plugin == null) {
-				LOG.info("Ranger plugin not initialized yet! Skipping authorization;  allowedFlag => [" + accessAllowed + "], Audit Enabled:" + isAuditEnabled);
-			} else {
-				String userName = null;
-				String[] groups = null;
-	
-				Principal user = aRequestContext.principal();
-			
-				if (user != null) {
-					userName = user.getName();
-					if (userName != null) {
-						UserGroupInformation ugi = UserGroupInformation.createRemoteUser(userName);
-						userName = ugi.getShortUserName();
-						groups = ugi.getGroupNames();
-						if (LOG.isDebugEnabled()) {
-							LOG.debug("User found from principal [" + user.getName() + "] => user:[" + userName + "], groups:[" + StringUtil.toString(groups) + "]");
-						}
-					}
-				}
-				
-				
-				if (userName != null) {
-					String clientIp =  (aRequestContext.remoteAddress() == null ? null : aRequestContext.remoteAddress().getHostAddress() );
-					RangerAccessRequest accessRequest = plugin.buildAccessRequest(userName, groups, clientIp, topologyName, aOperationName);
-					RangerAccessResult result = plugin.isAccessAllowed(accessRequest);
-					accessAllowed = result != null && result.getIsAllowed();
-					isAuditEnabled = result != null && result.getIsAudited();
-				
-					if (LOG.isDebugEnabled()) {
-						LOG.debug("User found from principal [" + userName + "], groups [" + StringUtil.toString(groups) + "]: verifying using [" + plugin.getClass().getName() + "], allowedFlag => [" + accessAllowed + "], Audit Enabled:" + isAuditEnabled);
-					}
-				}
-				else {
-					LOG.info("NULL User found from principal [" + user + "]: Skipping authorization;  allowedFlag => [" + accessAllowed + "], Audit Enabled:" + isAuditEnabled);
-				}
-			}
-		}
-		catch(Throwable t) {
-			LOG.error("RangerStormAuthorizer found this exception", t);
-		}
-		finally {
-			RangerPerfTracer.log(perf);
-			if (LOG.isDebugEnabled()) {
-				LOG.debug("[req "+ aRequestContext.requestID()+ "] Access "
-		                + " from: [" + aRequestContext.remoteAddress() + "]"
-		                + " user: [" + aRequestContext.principal() + "],"
-		                + " op:   [" + aOperationName + "],"
-		                + "topology: [" + topologyName + "] => returns [" + accessAllowed + "], Audit Enabled:" + isAuditEnabled);
-			}
-		}
-		
-		return accessAllowed;
-	}
-	
-	/**
-     * Invoked once immediately after construction
-     * @param aStormConfigMap Storm configuration
-     */
-
-	@Override
-	public void prepare(Map aStormConfigMap) {
-		StormRangerPlugin me = plugin;
-
-		if (me == null) {
-			synchronized(RangerStormAuthorizer.class) {
-				me = plugin;
-
-				if (me == null) {
-					try {
-						MiscUtil.setUGIFromJAASConfig(STORM_CLIENT_JASS_CONFIG_SECTION);
-						LOG.info("LoginUser=" + MiscUtil.getUGILoginUser());
-					} catch (Throwable t) {
-						LOG.error("Error while setting UGI for Storm Plugin...", t);
-					}
-
-					LOG.info("Creating StormRangerPlugin");
-
-					plugin = new StormRangerPlugin();
-					plugin.init();
-				}
-			}
-		}
-	}
-
-}
diff --git a/storm-agent/src/main/java/org/apache/ranger/services/storm/RangerServiceStorm.java b/storm-agent/src/main/java/org/apache/ranger/services/storm/RangerServiceStorm.java
deleted file mode 100644
index ffe26b617..000000000
--- a/storm-agent/src/main/java/org/apache/ranger/services/storm/RangerServiceStorm.java
+++ /dev/null
@@ -1,128 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- * http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-package org.apache.ranger.services.storm;
-
-import java.util.ArrayList;
-import java.util.Collections;
-import java.util.HashMap;
-import java.util.List;
-import java.util.Map;
-
-import org.apache.commons.lang.StringUtils;
-import org.apache.ranger.plugin.model.RangerPolicy;
-import org.apache.ranger.plugin.model.RangerPolicy.RangerPolicyItem;
-import org.apache.ranger.plugin.model.RangerPolicy.RangerPolicyItemAccess;
-import org.apache.ranger.plugin.model.RangerService;
-import org.apache.ranger.plugin.model.RangerServiceDef;
-import org.apache.ranger.plugin.service.RangerBaseService;
-import org.apache.ranger.plugin.service.ResourceLookupContext;
-import org.apache.ranger.services.storm.client.StormResourceMgr;
-import org.apache.commons.logging.Log;
-import org.apache.commons.logging.LogFactory;
-
-public class RangerServiceStorm extends RangerBaseService {
-
-	private static final Log LOG = LogFactory.getLog(RangerServiceStorm.class);
-	public static final String ACCESS_TYPE_GET_TOPOLOGY  = "getTopology";
-	public static final String ACCESS_TYPE_GET_TOPOLOGY_CONF  = "getTopologyConf";
-	public static final String ACCESS_TYPE_GET_USER_TOPOLOGY  = "getUserTopology";
-	public static final String ACCESS_TYPE_GET_TOPOLOGY_INFO  = "getTopologyInfo";
-	
-	public RangerServiceStorm() {
-		super();
-	}
-	
-	@Override
-	public void init(RangerServiceDef serviceDef, RangerService service) {
-		super.init(serviceDef, service);
-	}
-
-	@Override
-	public List<RangerPolicy> getDefaultRangerPolicies() throws Exception {
-		if (LOG.isDebugEnabled()) {
-			LOG.debug("==> RangerServiceStorm.getDefaultRangerPolicies()");
-		}
-
-		List<RangerPolicy> ret = super.getDefaultRangerPolicies();
-		for (RangerPolicy defaultPolicy : ret) {
-			if (defaultPolicy.getName().contains("all") && StringUtils.isNotBlank(lookUpUser)) {
-				List<RangerPolicyItemAccess> accessListForLookupUser = new ArrayList<RangerPolicyItemAccess>();
-				accessListForLookupUser.add(new RangerPolicyItemAccess(ACCESS_TYPE_GET_TOPOLOGY));
-				accessListForLookupUser.add(new RangerPolicyItemAccess(ACCESS_TYPE_GET_TOPOLOGY_CONF));
-				accessListForLookupUser.add(new RangerPolicyItemAccess(ACCESS_TYPE_GET_USER_TOPOLOGY));
-				accessListForLookupUser.add(new RangerPolicyItemAccess(ACCESS_TYPE_GET_TOPOLOGY_INFO));
-				RangerPolicyItem policyItemForLookupUser = new RangerPolicyItem();
-				policyItemForLookupUser.setUsers(Collections.singletonList(lookUpUser));
-				policyItemForLookupUser.setAccesses(accessListForLookupUser);
-				policyItemForLookupUser.setDelegateAdmin(false);
-				defaultPolicy.getPolicyItems().add(policyItemForLookupUser);
-			}
-		}
-
-		if (LOG.isDebugEnabled()) {
-			LOG.debug("<== RangerServiceStorm.getDefaultRangerPolicies()");
-		}
-		return ret;
-	}
-
-	@Override
-	public Map<String,Object> validateConfig() throws Exception {
-		Map<String, Object> ret = new HashMap<String, Object>();
-		String 	serviceName  	    = getServiceName();
-		if(LOG.isDebugEnabled()) {
-			LOG.debug("==> RangerServiceStorm.validateConfig Service: (" + serviceName + " )");
-		}
-		if ( configs != null) {
-			try  {
-				ret = StormResourceMgr.validateConfig(serviceName, configs);
-			} catch (Exception e) {
-				LOG.error("<== RangerServiceStorm.validateConfig Error:" + e);
-				throw e;
-			}
-		}
-		if(LOG.isDebugEnabled()) {
-			LOG.debug("<== RangerServiceStorm.validateConfig Response : (" + ret + " )");
-		}
-		return ret;
-	}
-
-	@Override
-	public List<String> lookupResource(ResourceLookupContext context) throws Exception {
-		
-		List<String> ret = new ArrayList<String>();
-		String 	serviceName  	   = getServiceName();
-		Map<String,String> configs = getConfigs();
-		if(LOG.isDebugEnabled()) {
-			LOG.debug("==> RangerServiceStorm.lookupResource Context: (" + context + ")");
-		}
-		if (context != null) {
-			try {
-				ret  = StormResourceMgr.getStormResources(serviceName,configs,context);
-						
-			} catch (Exception e) {
-			  LOG.error( "<==RangerServiceStorm.lookupResource Error : " + e);
-			  throw e;
-			}
-		}
-		if(LOG.isDebugEnabled()) {
-			LOG.debug("<== RangerServiceStorm.lookupResource Response: (" + ret + ")");
-		}
-		return ret;
-	}
-}
\ No newline at end of file
diff --git a/storm-agent/src/main/java/org/apache/ranger/services/storm/client/StormClient.java b/storm-agent/src/main/java/org/apache/ranger/services/storm/client/StormClient.java
deleted file mode 100644
index 46e370ebe..000000000
--- a/storm-agent/src/main/java/org/apache/ranger/services/storm/client/StormClient.java
+++ /dev/null
@@ -1,451 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- * http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-
-package org.apache.ranger.services.storm.client;
-
-import java.io.IOException;
-import java.security.PrivilegedAction;
-import java.util.ArrayList;
-import java.util.HashMap;
-import java.util.List;
-import java.util.Map;
-
-import javax.security.auth.Subject;
-import javax.security.auth.login.AppConfigurationEntry;
-import javax.security.auth.login.AppConfigurationEntry.LoginModuleControlFlag;
-import javax.security.auth.login.LoginContext;
-import javax.security.auth.login.LoginException;
-
-import org.apache.commons.io.FilenameUtils;
-import org.apache.commons.lang.StringUtils;
-import org.apache.hadoop.security.KrbPasswordSaverLoginModule;
-import org.apache.hadoop.security.SecureClientLogin;
-import org.apache.hadoop.security.authentication.util.KerberosUtil;
-import org.apache.log4j.Logger;
-import org.apache.ranger.plugin.client.BaseClient;
-import org.apache.ranger.plugin.client.HadoopException;
-import org.apache.ranger.plugin.util.PasswordUtils;
-import org.apache.ranger.services.storm.client.json.model.Topology;
-import org.apache.ranger.services.storm.client.json.model.TopologyListResponse;
-
-import com.google.gson.Gson;
-import com.google.gson.GsonBuilder;
-import com.sun.jersey.api.client.Client;
-import com.sun.jersey.api.client.ClientResponse;
-import com.sun.jersey.api.client.WebResource;
-
-public class StormClient {
-
-	private static final Logger LOG = Logger.getLogger(StormClient.class);
-
-	private static final String EXPECTED_MIME_TYPE = "application/json";
-
-	private static final String TOPOLOGY_LIST_API_ENDPOINT = "/api/v1/topology/summary";
-
-	private static final String errMessage =  " You can still save the repository and start creating "
-											  + "policies, but you would not be able to use autocomplete for "
-											  + "resource names. Check ranger_admin.log for more info.";
-
-	String stormUIUrl;
-	String userName;
-	String password;
-	String lookupPrincipal;
-	String lookupKeytab;
-	String nameRules;
-
-	public StormClient(String aStormUIUrl, String aUserName, String aPassword, String lookupPrincipal, String lookupKeytab, String nameRules) {
-
-		this.stormUIUrl = aStormUIUrl;
-		this.userName = aUserName;
-		this.password = aPassword;
-		this.lookupPrincipal = lookupPrincipal;
-		this.lookupKeytab = lookupKeytab;
-		this.nameRules = nameRules;
-
-		if (LOG.isDebugEnabled()) {
-			LOG.debug("Storm Client is build with url [" + aStormUIUrl + "] user: [" + aUserName + "], password: [" + "" + "]");
-		}
-
-	}
-
-	public List<String> getTopologyList(final String topologyNameMatching, final List<String> stormTopologyList) {
-
-		if (LOG.isDebugEnabled()) {
-			LOG.debug("Getting Storm topology list for topologyNameMatching : " + topologyNameMatching);
-		}
-
-		PrivilegedAction<ArrayList<String>> topologyListGetter = new PrivilegedAction<ArrayList<String>>() {
-			@Override
-			public ArrayList<String> run() {
-				if (stormUIUrl == null || stormUIUrl.trim().isEmpty()) {
-					return null;
-				}
-
-				String[] stormUIUrls = stormUIUrl.trim().split("[,;]");
-				if (stormUIUrls == null || stormUIUrls.length == 0) {
-					return null;
-				}
-
-				Client client = Client.create();
-				ClientResponse response = null;
-				for (String currentUrl : stormUIUrls) {
-					if (currentUrl == null || currentUrl.trim().isEmpty()) {
-						continue;
-					}
-
-					String url = currentUrl.trim() + TOPOLOGY_LIST_API_ENDPOINT;
-					try {
-						response = getTopologyResponse(url, client);
-
-						if (response != null) {
-							if (response.getStatus() == 200) {
-								break;
-							} else {
-								response.close();
-							}
-						}
-					} catch (Throwable t) {
-						String msgDesc = "Exception while getting topology list." + " URL : " + url;
-						LOG.error(msgDesc, t);
-					}
-				}
-
-				ArrayList<String> lret = new ArrayList<String>();
-				try {
-					if (response != null) {
-						if (LOG.isDebugEnabled()) {
-							LOG.debug("getTopologyList():response.getStatus()= " + response.getStatus());
-						}
-						if (response.getStatus() == 200) {
-							String jsonString = response.getEntity(String.class);
-							Gson gson = new GsonBuilder().setPrettyPrinting().create();
-							TopologyListResponse topologyListResponse = gson.fromJson(jsonString, TopologyListResponse.class);
-							if (topologyListResponse != null) {
-								if (topologyListResponse.getTopologyList() != null) {
-									for (Topology topology : topologyListResponse.getTopologyList()) {
-										String topologyName = topology.getName();
-										if (stormTopologyList != null && stormTopologyList.contains(topologyName)) {
-											continue;
-										}
-										if (LOG.isDebugEnabled()) {
-											LOG.debug("getTopologyList():Found topology " + topologyName);
-											LOG.debug("getTopologyList():topology Name=[" + topology.getName()
-													+ "], topologyNameMatching=[" + topologyNameMatching
-													+ "], existingStormTopologyList=[" + stormTopologyList + "]");
-										}
-										if (topologyName != null) {
-											if (topologyNameMatching == null || topologyNameMatching.isEmpty() || FilenameUtils.wildcardMatch(topology.getName(), topologyNameMatching + "*")) {
-												if (LOG.isDebugEnabled()) {
-													LOG.debug("getTopologyList():Adding topology " + topologyName);
-												}
-												lret.add(topologyName);
-											}
-										}
-									}
-								}
-							}
-						}
-					} else {
-						String msgDesc = "Unable to get a valid response for " + "expected mime type : ["
-								+ EXPECTED_MIME_TYPE + "] URL : " + stormUIUrl + " - got null response.";
-						LOG.error(msgDesc);
-						HadoopException hdpException = new HadoopException(msgDesc);
-						hdpException.generateResponseDataMap(false, msgDesc, msgDesc + errMessage, null, null);
-						throw hdpException;
-					}
-				} catch (HadoopException he) {
-					throw he;
-				} catch (Throwable t) {
-					String msgDesc = "Exception while getting Storm TopologyList." + " URL : " + stormUIUrl;
-					HadoopException hdpException = new HadoopException(msgDesc, t);
-					LOG.error(msgDesc, t);
-
-					hdpException.generateResponseDataMap(false, BaseClient.getMessage(t), msgDesc + errMessage, null, null);
-					throw hdpException;
-				} finally {
-					if (response != null) {
-						response.close();
-					}
-
-					if (client != null) {
-						client.destroy();
-					}
-				}
-				return lret;
-			}
-
-			private ClientResponse getTopologyResponse(String url, Client client) {
-				if (LOG.isDebugEnabled()) {
-					LOG.debug("getTopologyResponse():calling " + url);
-				}
-
-				WebResource webResource = client.resource(url);
-
-				ClientResponse response = webResource.accept(EXPECTED_MIME_TYPE).get(ClientResponse.class);
-
-				if (response != null) {
-					if (LOG.isDebugEnabled()) {
-						LOG.debug("getTopologyResponse():response.getStatus()= " + response.getStatus());
-					}
-					if (response.getStatus() != 200) {
-						LOG.info("getTopologyResponse():response.getStatus()= " + response.getStatus() + " for URL "
-								+ url + ", failed to get topology list");
-						String jsonString = response.getEntity(String.class);
-						LOG.info(jsonString);
-					}
-				}
-				return response;
-			}
-		};
-
-		List<String> ret = null;
-		try {
-			ret = executeUnderKerberos(this.userName, this.password, this.lookupPrincipal, this.lookupKeytab, this.nameRules, topologyListGetter);
-		} catch (IOException e) {
-			LOG.error("Unable to get Topology list from [" + stormUIUrl + "]", e);
-		}
-
-		return ret;
-	}
-
-	public static <T> T executeUnderKerberos(String userName, String password, String lookupPrincipal, String lookupKeytab, String nameRules,
-			PrivilegedAction<T> action) throws IOException {
-
-		T ret = null;
-
-		Subject subject = null;
-		LoginContext loginContext = null;
-
-		try {
-			Subject loginSubj = null;
-			if(!StringUtils.isEmpty(lookupPrincipal) && !StringUtils.isEmpty(lookupKeytab)){
-				LOG.info("Init Lookup Login: security enabled, using lookupPrincipal/lookupKeytab");
-				if(StringUtils.isEmpty(nameRules)){
-					nameRules = "DEFAULT";
-				}
-				loginSubj = SecureClientLogin.loginUserFromKeytab(lookupPrincipal, lookupKeytab, nameRules);
-			}else{
-			    subject = new Subject();
-				LOG.debug("executeUnderKerberos():user=" + userName + ",pass=");
-				LOG.debug("executeUnderKerberos():Creating config..");
-				MySecureClientLoginConfiguration loginConf = new MySecureClientLoginConfiguration(
-						userName, password);
-				LOG.debug("executeUnderKerberos():Creating Context..");
-				loginContext = new LoginContext("hadoop-keytab-kerberos", subject,
-						null, loginConf);
-
-				LOG.debug("executeUnderKerberos():Logging in..");
-				loginContext.login();
-				LOG.info("Init Login: using username/password");
-				loginSubj = loginContext.getSubject();
-			}
-			if (loginSubj != null) {
-				ret = Subject.doAs(loginSubj, action);
-			}
-		} catch (LoginException le) {
-			String msgDesc = "executeUnderKerberos: Login failure using given"
-					+ " configuration parameters, username : `" + userName + "`.";
-			HadoopException hdpException = new HadoopException(msgDesc, le);
-			LOG.error(msgDesc, le);
-
-			hdpException.generateResponseDataMap(false,
-					BaseClient.getMessage(le), msgDesc + errMessage, null, null);
-			throw hdpException;
-		} catch (SecurityException se) {
-			String msgDesc = "executeUnderKerberos: Exception while getting Storm TopologyList.";
-			HadoopException hdpException = new HadoopException(msgDesc, se);
-			LOG.error(msgDesc, se);
-
-			hdpException.generateResponseDataMap(false,
-					BaseClient.getMessage(se), msgDesc + errMessage, null, null);
-			throw hdpException;
-
-		} finally {
-			if (loginContext != null) {
-				if (subject != null) {
-					try {
-						loginContext.logout();
-					} catch (LoginException e) {
-						throw new IOException("logout failure", e);
-					}
-				}
-			}
-		}
-
-		return ret;
-	}
-
-	public static Map<String, Object> connectionTest(String serviceName,
-			Map<String, String> configs) {
-
-		String errMsg = errMessage;
-		boolean connectivityStatus = false;
-		Map<String, Object> responseData = new HashMap<String, Object>();
-
-		StormClient stormClient = getStormClient(serviceName,
-				configs);
-		List<String> strList = getStormResources(stormClient, "",null);
-
-		if (strList != null) {
-			connectivityStatus = true;
-		}
-
-		if (connectivityStatus) {
-			String successMsg = "ConnectionTest Successful";
-			BaseClient.generateResponseDataMap(connectivityStatus, successMsg,
-					successMsg, null, null, responseData);
-		} else {
-			String failureMsg = "Unable to retrieve any topologies using given parameters.";
-			BaseClient.generateResponseDataMap(connectivityStatus, failureMsg,
-					failureMsg + errMsg, null, null, responseData);
-		}
-
-		return responseData;
-	}
-
-	public static StormClient getStormClient(String serviceName,
-			Map<String, String> configs) {
-		StormClient stormClient = null;
-		if(LOG.isDebugEnabled()){
-			LOG.debug("Getting StormClient for datasource: " + serviceName);
-			LOG.debug("configMap: " + configs);
-		}
-		String errMsg = errMessage;
-		if (configs == null || configs.isEmpty()) {
-			String msgDesc = "Could not connect as Connection ConfigMap is empty.";
-			LOG.error(msgDesc);
-			HadoopException hdpException = new HadoopException(msgDesc);
-			hdpException.generateResponseDataMap(false, msgDesc, msgDesc
-					+ errMsg, null, null);
-			throw hdpException;
-		} else {
-			String stormUrl = configs.get("nimbus.url");
-			String stormAdminUser = configs.get("username");
-			String stormAdminPassword = configs.get("password");
-			String lookupPrincipal = configs.get("lookupprincipal");
-			String lookupKeytab = configs.get("lookupkeytab");
-			String nameRules = configs.get("namerules");
-			stormClient = new StormClient(stormUrl, stormAdminUser,
-					stormAdminPassword, lookupPrincipal, lookupKeytab, nameRules);
-		}
-		return stormClient;
-	}
-
-	public static List<String> getStormResources(final StormClient stormClient,
-			String topologyName, List<String> stormTopologyList) {
-
-		List<String> resultList = new ArrayList<String>();
-		String errMsg = errMessage;
-
-		try {
-			if (stormClient == null) {
-				String msgDesc = "Unable to get Storm resources: StormClient is null.";
-				LOG.error(msgDesc);
-				HadoopException hdpException = new HadoopException(msgDesc);
-				hdpException.generateResponseDataMap(false, msgDesc, msgDesc
-						+ errMsg, null, null);
-				throw hdpException;
-			}
-
-			if (topologyName != null) {
-				String finalTopologyNameMatching = topologyName.trim();
-				resultList = stormClient
-						.getTopologyList(finalTopologyNameMatching,stormTopologyList);
-				if (resultList != null) {
-					LOG.debug("Returning list of " + resultList.size() + " topologies");
-				}
-			}
-		} catch (HadoopException he) {
-			throw he;
-		} catch (Exception e) {
-			String msgDesc = "getStormResources: Unable to get Storm resources.";
-			LOG.error(msgDesc, e);
-			HadoopException hdpException = new HadoopException(msgDesc);
-
-			hdpException.generateResponseDataMap(false,
-					BaseClient.getMessage(e), msgDesc + errMsg, null, null);
-			throw hdpException;
-		}
-		return resultList;
-	}
-
-	private static class MySecureClientLoginConfiguration extends javax.security.auth.login.Configuration {
-
-	    private String userName;
-	    private String password;
-
-	    MySecureClientLoginConfiguration(String aUserName, String password) {
-	        this.userName = aUserName;
-	        String decryptedPwd = null;
-	        try {
-	            decryptedPwd = PasswordUtils.decryptPassword(password);
-	        } catch(Exception ex) {
-	            LOG.info("Password decryption failed; trying Storm connection with received password string");
-	            decryptedPwd = null;
-	        } finally {
-	            if (decryptedPwd == null) {
-	                decryptedPwd = password;
-	            }
-	        }
-	        this.password = decryptedPwd;
-	    }
-
-	    @Override
-	    public AppConfigurationEntry[] getAppConfigurationEntry(String appName) {
-
-	        Map<String, String> kerberosOptions = new HashMap<String, String>();
-	        kerberosOptions.put("principal", this.userName);
-	        kerberosOptions.put("debug", "true");
-	        kerberosOptions.put("useKeyTab", "false");
-	        kerberosOptions.put(KrbPasswordSaverLoginModule.USERNAME_PARAM, this.userName);
-	        kerberosOptions.put(KrbPasswordSaverLoginModule.PASSWORD_PARAM, this.password);
-	        kerberosOptions.put("doNotPrompt", "false");
-	        kerberosOptions.put("useFirstPass", "true");
-	        kerberosOptions.put("tryFirstPass", "false");
-	        kerberosOptions.put("storeKey", "true");
-	        kerberosOptions.put("refreshKrb5Config", "true");
-
-	        AppConfigurationEntry KEYTAB_KERBEROS_LOGIN = null;
-	        AppConfigurationEntry KERBEROS_PWD_SAVER = null;
-	        try {
-	            KEYTAB_KERBEROS_LOGIN = new AppConfigurationEntry(KerberosUtil.getKrb5LoginModuleName(),
-	                                                              AppConfigurationEntry.LoginModuleControlFlag.REQUIRED,
-	                                                              kerberosOptions);
-	            KERBEROS_PWD_SAVER = new AppConfigurationEntry(KrbPasswordSaverLoginModule.class.getName(),
-	                                                           LoginModuleControlFlag.REQUIRED, kerberosOptions);
-
-	        } catch (IllegalArgumentException e) {
-	            String msgDesc = "executeUnderKerberos: Exception while getting Storm TopologyList.";
-	            HadoopException hdpException = new HadoopException(msgDesc, e);
-	            LOG.error(msgDesc, e);
-
-	            hdpException.generateResponseDataMap(false,
-	                                                 BaseClient.getMessage(e), msgDesc + errMessage, null,
-	                                                 null);
-	            throw hdpException;
-	        }
-
-	        LOG.debug("getAppConfigurationEntry():" + kerberosOptions.get("principal"));
-
-	        return new AppConfigurationEntry[] { KERBEROS_PWD_SAVER, KEYTAB_KERBEROS_LOGIN };
-	    }
-
-	};
-}
-
diff --git a/storm-agent/src/main/java/org/apache/ranger/services/storm/client/StormConnectionMgr.java b/storm-agent/src/main/java/org/apache/ranger/services/storm/client/StormConnectionMgr.java
deleted file mode 100644
index ab1b409a4..000000000
--- a/storm-agent/src/main/java/org/apache/ranger/services/storm/client/StormConnectionMgr.java
+++ /dev/null
@@ -1,46 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- * http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-
-package org.apache.ranger.services.storm.client;
-
-import org.apache.commons.lang.StringUtils;
-import org.apache.log4j.Logger;
-
-
-public class StormConnectionMgr {
-
-	private static final Logger LOG = Logger.getLogger(StormConnectionMgr.class);
-
-	public static StormClient getStormClient(final String stormUIURL, String userName, String password, String lookupPrincipal, String lookupKeytab, String nameRules) {
-        StormClient stormClient = null;
-        if (stormUIURL == null || stormUIURL.isEmpty()) {
-        	LOG.error("Can not create StormClient: stormUIURL is empty");
-        } else if(StringUtils.isEmpty(lookupPrincipal) || StringUtils.isEmpty(lookupKeytab)){
-        	if (userName == null || userName.isEmpty()) {
-        		LOG.error("Can not create StormClient: stormAdminUser is empty");
-        	} else if (password == null || password.isEmpty()) {
-        		LOG.error("Can not create StormClient: stormAdminPassword is empty");
-        	}
-        }else {
-            stormClient =  new StormClient(stormUIURL, userName, password, lookupPrincipal, lookupKeytab, nameRules);
-        }
-        return stormClient;
-    }
-
-}
diff --git a/storm-agent/src/main/java/org/apache/ranger/services/storm/client/StormResourceMgr.java b/storm-agent/src/main/java/org/apache/ranger/services/storm/client/StormResourceMgr.java
deleted file mode 100644
index 0dd550793..000000000
--- a/storm-agent/src/main/java/org/apache/ranger/services/storm/client/StormResourceMgr.java
+++ /dev/null
@@ -1,97 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- * http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-
-package org.apache.ranger.services.storm.client;
-
-import java.util.ArrayList;
-import java.util.List;
-import java.util.Map;
-
-import org.apache.log4j.Logger;
-import org.apache.ranger.plugin.service.ResourceLookupContext;
-
-public class StormResourceMgr {
-	private static final 	Logger 	LOG 		= Logger.getLogger(StormResourceMgr.class);
-	private static final 	String  TOPOLOGY	= "topology";
-	
-	public static Map<String, Object> validateConfig(String serviceName, Map<String, String> configs) throws Exception {
-		Map<String, Object> ret = null;
-		
-		if(LOG.isDebugEnabled()) {
-			LOG.debug("==> StormResourceMgr.validateConfig ServiceName: "+ serviceName + "Configs" + configs );
-		}	
-		
-		try {
-			ret = StormClient.connectionTest(serviceName, configs);
-		} catch (Exception e) {
-			LOG.error("<== StormResourceMgr.validateConfig Error: " + e);
-		  throw e;
-		}
-		
-		if(LOG.isDebugEnabled()) {
-			LOG.debug("<== StormResourceMgr.validateConfig Result : "+ ret  );
-		}	
-		return ret;
-	}
-	
-    public static List<String> getStormResources(String serviceName, Map<String, String> configs,ResourceLookupContext context) {
-        String 		 userInput 				  = context.getUserInput();
-		Map<String, List<String>> resourceMap = context.getResources();
-	    List<String> 		resultList        = null;
-		List<String> 		StormTopologyList = null;
-		String  			stormTopologyName = null;
-		
-		if ( resourceMap != null && !resourceMap.isEmpty() &&
-			resourceMap.get(TOPOLOGY) != null ) {
-			stormTopologyName = userInput;
-			StormTopologyList = resourceMap.get(TOPOLOGY);
-		} else {
-			stormTopologyName = userInput;
-		}
-		
-		
-        if (configs == null || configs.isEmpty()) {
-                LOG.error("Connection Config is empty");
-
-        } else {
-                String url 		= configs.get("nimbus.url");
-                String username = configs.get("username");
-                String password = configs.get("password");
-                String lookupPrincipal = configs.get("lookupprincipal");
-                String lookupKeytab = configs.get("lookupkeytab");
-                String nameRules = configs.get("namerules");
-                resultList = getStormResources(url, username, password,lookupPrincipal, lookupKeytab, nameRules, stormTopologyName,StormTopologyList);
-        }
-        return resultList;
-    }
-
-    public static List<String> getStormResources(String url, String username, String password, String lookupPrincipal, String lookupKeytab, String nameRules, String topologyName, List<String> StormTopologyList) {
-    	List<String> topologyList	  = null;
-        final StormClient stormClient = StormConnectionMgr.getStormClient(url, username, password, lookupPrincipal, lookupKeytab, nameRules);
-	    if (stormClient == null) {
-		    LOG.error("Storm Client is null");
-		    return new ArrayList<String>();
-	    }
-	    synchronized(stormClient){
-	    	topologyList = stormClient.getTopologyList(topologyName,StormTopologyList);
-	    }
-        return topologyList;
-    }
-
-}
diff --git a/storm-agent/src/main/java/org/apache/ranger/services/storm/client/json/model/Topology.java b/storm-agent/src/main/java/org/apache/ranger/services/storm/client/json/model/Topology.java
deleted file mode 100644
index 2d7f80bf1..000000000
--- a/storm-agent/src/main/java/org/apache/ranger/services/storm/client/json/model/Topology.java
+++ /dev/null
@@ -1,47 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- * http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-
-package org.apache.ranger.services.storm.client.json.model;
-
-public class Topology {
-	private String id;
-	private String name;
-	private String status;
-	
-	public String getId() {
-		return id;
-	}
-	public void setId(String id) {
-		this.id = id;
-	}
-	public String getName() {
-		return name;
-	}
-	public void setName(String name) {
-		this.name = name;
-	}
-	public String getStatus() {
-		return status;
-	}
-	public void setStatus(String status) {
-		this.status = status;
-	}
-	
-	
-}
diff --git a/storm-agent/src/main/java/org/apache/ranger/services/storm/client/json/model/TopologyListResponse.java b/storm-agent/src/main/java/org/apache/ranger/services/storm/client/json/model/TopologyListResponse.java
deleted file mode 100644
index a06ad0803..000000000
--- a/storm-agent/src/main/java/org/apache/ranger/services/storm/client/json/model/TopologyListResponse.java
+++ /dev/null
@@ -1,38 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- * http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-
-package org.apache.ranger.services.storm.client.json.model;
-
-import java.util.List;
-
-import com.google.gson.annotations.SerializedName;
-
-public class TopologyListResponse {
-	@SerializedName("topologies")
-	private List<Topology>	topologyList;
-
-	public List<Topology> getTopologyList() {
-		return topologyList;
-	}
-
-	public void setTopologyList(List<Topology> topologyList) {
-		this.topologyList = topologyList;
-	}
-	
-}
diff --git a/storm-agent/src/test/java/org/apache/ranger/authorization/storm/RangerAdminClientImpl.java b/storm-agent/src/test/java/org/apache/ranger/authorization/storm/RangerAdminClientImpl.java
deleted file mode 100644
index 2b402054b..000000000
--- a/storm-agent/src/test/java/org/apache/ranger/authorization/storm/RangerAdminClientImpl.java
+++ /dev/null
@@ -1,85 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *      http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.ranger.authorization.storm;
-
-import java.io.File;
-import java.nio.file.FileSystems;
-import java.nio.file.Files;
-import java.util.List;
-
-import org.apache.hadoop.conf.Configuration;
-import org.apache.ranger.admin.client.AbstractRangerAdminClient;
-import org.apache.ranger.plugin.util.ServicePolicies;
-import org.apache.ranger.plugin.util.ServiceTags;
-import org.slf4j.Logger;
-import org.slf4j.LoggerFactory;
-
-import com.google.gson.Gson;
-import com.google.gson.GsonBuilder;
-
-/**
- * A test implementation of the RangerAdminClient interface that just reads policies in from a file and returns them
- */
-public class RangerAdminClientImpl extends AbstractRangerAdminClient {
-    private static final Logger LOG = LoggerFactory.getLogger(RangerAdminClientImpl.class);
-    private final static String cacheFilename = "storm-policies.json";
-    private final static String tagFilename = "storm-policies-tag.json";
-    private Gson gson;
-
-    @Override
-    public void init(String serviceName, String appId, String configPropertyPrefix, Configuration config) {
-        Gson gson = null;
-        try {
-            gson = new GsonBuilder().setDateFormat("yyyyMMdd-HH:mm:ss.SSS-Z").setPrettyPrinting().create();
-        } catch(Throwable excp) {
-            LOG.error("RangerAdminClientImpl: failed to create GsonBuilder object", excp);
-        }
-        this.gson = gson;
-    }
-
-    public ServicePolicies getServicePoliciesIfUpdated(long lastKnownVersion, long lastActivationTimeInMillis) throws Exception {
-
-        String basedir = System.getProperty("basedir");
-        if (basedir == null) {
-            basedir = new File(".").getCanonicalPath();
-        }
-
-        java.nio.file.Path cachePath = FileSystems.getDefault().getPath(basedir, "/src/test/resources/" + cacheFilename);
-        byte[] cacheBytes = Files.readAllBytes(cachePath);
-
-        return gson.fromJson(new String(cacheBytes), ServicePolicies.class);
-    }
-
-    public ServiceTags getServiceTagsIfUpdated(long lastKnownVersion, long lastActivationTimeInMillis) throws Exception {
-        String basedir = System.getProperty("basedir");
-        if (basedir == null) {
-            basedir = new File(".").getCanonicalPath();
-        }
-
-        java.nio.file.Path cachePath = FileSystems.getDefault().getPath(basedir, "/src/test/resources/" + tagFilename);
-        byte[] cacheBytes = Files.readAllBytes(cachePath);
-
-        return gson.fromJson(new String(cacheBytes), ServiceTags.class);
-    }
-
-    public List<String> getTagTypes(String tagTypePattern) throws Exception {
-        return null;
-    }
-
-
-}
\ No newline at end of file
diff --git a/storm-agent/src/test/java/org/apache/ranger/authorization/storm/StormRangerAuthorizerTest.java b/storm-agent/src/test/java/org/apache/ranger/authorization/storm/StormRangerAuthorizerTest.java
deleted file mode 100644
index 90b0c03e3..000000000
--- a/storm-agent/src/test/java/org/apache/ranger/authorization/storm/StormRangerAuthorizerTest.java
+++ /dev/null
@@ -1,231 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *      http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.ranger.authorization.storm;
-
-import java.security.Principal;
-import java.security.PrivilegedExceptionAction;
-
-import javax.security.auth.Subject;
-
-import org.apache.storm.Config;
-import org.apache.storm.LocalCluster;
-import org.apache.storm.generated.RebalanceOptions;
-import org.apache.storm.topology.TopologyBuilder;
-import org.junit.Assert;
-import org.junit.Test;
-import org.junit.Ignore;
-
-/**
- * A simple test that wires a WordSpout + WordCounterBolt into a topology and runs it. The "RangerStormAuthorizer" takes care of authorization.
- * The policies state that "bob" can do anything with the "word-count" topology. In addition, "bob" can create/kill the "temp*" topologies, but do
- * nothing else.
- *
- * In addition we have some TAG based policies created in Atlas and synced into Ranger:
- *
- * a) The tag "StormTopologyTag" is associated with "create/kill" permissions to the "bob" user for the "stormdev" topology.
- */
-
-// TODO to fix Strom Test working with Hadoop 3.0.0
-@Ignore
-public class StormRangerAuthorizerTest {
-
-    private static LocalCluster cluster;
-
-    @org.junit.BeforeClass
-    public static void setup() throws Exception {
-        cluster = new LocalCluster();
-
-        final Config conf = new Config();
-        conf.setDebug(true);
-
-        final TopologyBuilder builder = new TopologyBuilder();
-        builder.setSpout("words", new WordSpout());
-        builder.setBolt("counter", new WordCounterBolt()).shuffleGrouping("words");
-
-        // bob can create a new topology
-        final Subject subject = new Subject();
-        subject.getPrincipals().add(new SimplePrincipal("bob"));
-        Subject.doAs(subject, new PrivilegedExceptionAction<Void>() {
-            public Void run() throws Exception {
-                cluster.submitTopology("word-count", conf, builder.createTopology());
-                return null;
-            }
-        });
-
-    }
-
-    @org.junit.AfterClass
-    public static void cleanup() throws Exception {
-        final Subject subject = new Subject();
-        subject.getPrincipals().add(new SimplePrincipal("bob"));
-        Subject.doAs(subject, new PrivilegedExceptionAction<Void>() {
-            public Void run() throws Exception {
-                cluster.killTopology("word-count");
-                return null;
-            }
-        });
-
-        cluster.shutdown();
-        System.clearProperty("storm.conf.file");
-    }
-
-    // "bob" can't create topologies other than "word-count" and "temp*"
-    @Test
-    public void testCreateTopologyBob() throws Exception {
-        final Config conf = new Config();
-        conf.setDebug(true);
-
-        final TopologyBuilder builder = new TopologyBuilder();
-        builder.setSpout("words", new WordSpout());
-        builder.setBolt("counter", new WordCounterBolt()).shuffleGrouping("words");
-
-        final Subject subject = new Subject();
-        subject.getPrincipals().add(new SimplePrincipal("bob"));
-        Subject.doAs(subject, new PrivilegedExceptionAction<Void>() {
-            public Void run() throws Exception {
-                try {
-                    cluster.submitTopology("word-count2", conf, builder.createTopology());
-                    Assert.fail("Authorization failure expected");
-                } catch (Exception ex) {
-                    // expected
-                }
-
-                return null;
-            }
-        });
-    }
-
-    @Test
-    public void testTopologyActivation() throws Exception {
-        final Subject subject = new Subject();
-        subject.getPrincipals().add(new SimplePrincipal("bob"));
-        Subject.doAs(subject, new PrivilegedExceptionAction<Void>() {
-            public Void run() throws Exception {
-
-                // Deactivate "word-count"
-                cluster.deactivate("word-count");
-
-                // Create a new topology called "temp1"
-                final Config conf = new Config();
-                conf.setDebug(true);
-
-                final TopologyBuilder builder = new TopologyBuilder();
-                builder.setSpout("words", new WordSpout());
-                builder.setBolt("counter", new WordCounterBolt()).shuffleGrouping("words");
-                cluster.submitTopology("temp1", conf, builder.createTopology());
-
-                // Try to deactivate "temp1"
-                try {
-                    cluster.deactivate("temp1");
-                    Assert.fail("Authorization failure expected");
-                } catch (Exception ex) {
-                    // expected
-                }
-
-                // Re-activate "word-count"
-                cluster.activate("word-count");
-
-                // Kill temp1
-                cluster.killTopology("temp1");
-
-                return null;
-            }
-        });
-    }
-
-    @Test
-    public void testTopologyRebalancing() throws Exception {
-        final Subject subject = new Subject();
-        subject.getPrincipals().add(new SimplePrincipal("bob"));
-        Subject.doAs(subject, new PrivilegedExceptionAction<Void>() {
-            public Void run() throws Exception {
-                RebalanceOptions options = new RebalanceOptions();
-
-                // Create a new topology called "temp2"
-                final Config conf = new Config();
-                conf.setDebug(true);
-
-                final TopologyBuilder builder = new TopologyBuilder();
-                builder.setSpout("words", new WordSpout());
-                builder.setBolt("counter", new WordCounterBolt()).shuffleGrouping("words");
-                cluster.submitTopology("temp2", conf, builder.createTopology());
-
-                // Try to rebalance "temp2"
-                try {
-                    cluster.rebalance("temp2", options);
-                    Assert.fail("Authorization failure expected");
-                } catch (Exception ex) {
-                    // expected
-                }
-
-                // Kill temp2
-                cluster.killTopology("temp2");
-
-                return null;
-            }
-        });
-    }
-
-    @Test
-    public void testTAGBasedPolicy() throws Exception {
-        final Config conf = new Config();
-        conf.setDebug(true);
-
-        final TopologyBuilder builder = new TopologyBuilder();
-        builder.setSpout("words", new WordSpout());
-        builder.setBolt("counter", new WordCounterBolt()).shuffleGrouping("words");
-
-        final Subject subject = new Subject();
-
-        subject.getPrincipals().add(new SimplePrincipal("bob"));
-        Subject.doAs(subject, new PrivilegedExceptionAction<Void>() {
-            public Void run() throws Exception {
-                // bob can create the "stormdev" topology
-                cluster.submitTopology("stormdev", conf, builder.createTopology());
-
-                cluster.killTopology("stormdev");
-
-                // but not the "stormdev2" topology
-                try {
-                    cluster.submitTopology("stormdev2", conf, builder.createTopology());
-                    Assert.fail("Authorization failure expected");
-                } catch (Exception ex) {
-                    // expected
-                }
-
-                return null;
-            }
-        });
-
-    }
-
-    private static class SimplePrincipal implements Principal {
-
-        private final String name;
-
-        public SimplePrincipal(String name) {
-            this.name = name;
-        }
-
-        @Override
-        public String getName() {
-            return name;
-        }
-
-    }
-}
diff --git a/storm-agent/src/test/java/org/apache/ranger/authorization/storm/WordCounterBolt.java b/storm-agent/src/test/java/org/apache/ranger/authorization/storm/WordCounterBolt.java
deleted file mode 100644
index 68d9de795..000000000
--- a/storm-agent/src/test/java/org/apache/ranger/authorization/storm/WordCounterBolt.java
+++ /dev/null
@@ -1,66 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *      http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.ranger.authorization.storm;
-
-import java.util.HashMap;
-import java.util.Map;
-
-import org.apache.storm.task.OutputCollector;
-import org.apache.storm.task.TopologyContext;
-import org.apache.storm.topology.OutputFieldsDeclarer;
-import org.apache.storm.topology.base.BaseRichBolt;
-import org.apache.storm.tuple.Fields;
-import org.apache.storm.tuple.Tuple;
-import org.apache.storm.tuple.Values;
-
-/**
- * A Storm Bolt which reads in a word and counts it + outputs the word + current count
- */
-public class WordCounterBolt extends BaseRichBolt {
-    private OutputCollector outputCollector;
-    private Map<String, Integer> countMap = new HashMap<>();
-
-    @Override
-    public void execute(Tuple tuple) {
-        String word = tuple.getString(0);
-
-        int count = 0;
-        if (countMap.containsKey(word)) {
-            count = countMap.get(word);
-            count++;
-        }
-        count++;
-        countMap.put(word, count);
-
-        outputCollector.emit(new Values(word, count));
-        outputCollector.ack(tuple);
-
-    }
-
-    @Override
-    public void prepare(Map arg0, TopologyContext arg1, OutputCollector outputCollector) {
-        this.outputCollector = outputCollector;
-    }
-
-    @Override
-    public void declareOutputFields(OutputFieldsDeclarer declarer) {
-        declarer.declare(new Fields("word", "count"));
-    }
-
-
-}
diff --git a/storm-agent/src/test/java/org/apache/ranger/authorization/storm/WordSpout.java b/storm-agent/src/test/java/org/apache/ranger/authorization/storm/WordSpout.java
deleted file mode 100644
index 8ec950e28..000000000
--- a/storm-agent/src/test/java/org/apache/ranger/authorization/storm/WordSpout.java
+++ /dev/null
@@ -1,68 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *      http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.ranger.authorization.storm;
-
-import java.util.List;
-import java.util.Map;
-
-import org.apache.commons.io.IOUtils;
-import org.apache.storm.spout.SpoutOutputCollector;
-import org.apache.storm.task.TopologyContext;
-import org.apache.storm.topology.OutputFieldsDeclarer;
-import org.apache.storm.topology.base.BaseRichSpout;
-import org.apache.storm.tuple.Fields;
-import org.apache.storm.tuple.Values;
-
-/**
- * A Storm Spout which reads in words.txt + emits a word from it (sequentially)
- */
-public class WordSpout extends BaseRichSpout {
-    private final List<String> words;
-    private SpoutOutputCollector collector;
-    private int line = 0;
-
-    public WordSpout() throws Exception {
-        java.io.File inputFile = new java.io.File(WordSpout.class.getResource("../../../../../words.txt").toURI());
-        words = IOUtils.readLines(new java.io.FileInputStream(inputFile));
-    }
-
-    @Override
-    public void nextTuple() {
-        if (line < words.size()) {
-        	String lineVal = words.get(line++);
-        	while (lineVal.startsWith("#") && line < words.size()) {
-        		lineVal = words.get(line++);
-        	}
-        	if (lineVal != null) {
-        		collector.emit(new Values(lineVal.trim()));
-        	}
-        }
-    }
-
-    @Override
-    public void open(Map arg0, TopologyContext arg1, SpoutOutputCollector collector) {
-        this.collector = collector;
-    }
-
-    @Override
-    public void declareOutputFields(OutputFieldsDeclarer declarer) {
-        declarer.declare(new Fields("word"));
-    }
-
-
-}
diff --git a/storm-agent/src/test/resources/ranger-storm-security.xml b/storm-agent/src/test/resources/ranger-storm-security.xml
deleted file mode 100644
index 97510e5b9..000000000
--- a/storm-agent/src/test/resources/ranger-storm-security.xml
+++ /dev/null
@@ -1,45 +0,0 @@
-<?xml version="1.0"?>
-<!--
-  Licensed to the Apache Software Foundation (ASF) under one or more
-  contributor license agreements.  See the NOTICE file distributed with
-  this work for additional information regarding copyright ownership.
-  The ASF licenses this file to You under the Apache License, Version 2.0
-  (the "License"); you may not use this file except in compliance with
-  the License.  You may obtain a copy of the License at
-
-      http://www.apache.org/licenses/LICENSE-2.0
-
-  Unless required by applicable law or agreed to in writing, software
-  distributed under the License is distributed on an "AS IS" BASIS,
-  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-  See the License for the specific language governing permissions and
-  limitations under the License.
--->
-<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
-<configuration xmlns:xi="http://www.w3.org/2001/XInclude">
-
-	<property>
-		<name>ranger.plugin.storm.service.name</name>
-		<value>cl1_storm</value>
-		<description>
-			Name of the Ranger service containing policies for this SampleApp instance
-		</description>
-	</property>
-
-	<property>
-        <name>ranger.plugin.storm.policy.source.impl</name>
-        <value>org.apache.ranger.authorization.storm.RangerAdminClientImpl</value>
-        <description>
-            Policy source.
-        </description>
-    </property>
-    
-	<property>
-		<name>ranger.plugin.storm.policy.cache.dir</name>
-		<value>${project.build.directory}</value>
-		<description>
-			Directory where Ranger policies are cached after successful retrieval from the source
-		</description>
-	</property>
-
-</configuration>
diff --git a/storm-agent/src/test/resources/storm-policies-tag.json b/storm-agent/src/test/resources/storm-policies-tag.json
deleted file mode 100644
index 31bfbc879..000000000
--- a/storm-agent/src/test/resources/storm-policies-tag.json
+++ /dev/null
@@ -1,37 +0,0 @@
-{
-  "op": "add_or_update",
-  "serviceName": "cl1_storm",
-  "tagVersion": 2,
-  "tagDefinitions": {},
-  "tags": {
-    "1": {
-      "type": "StormTopologyTag",
-      "owner": 0,
-      "attributes": {},
-      "id": 1,
-      "isEnabled": true,
-      "version": 1
-    }
-  },
-  "serviceResources": [
-    {
-      "resourceElements": {
-        "topology": {
-          "values": [
-            "stormdev"
-          ],
-          "isExcludes": false,
-          "isRecursive": true
-        }
-      },
-      "id": 1,
-      "isEnabled": true,
-      "version": 5
-    }
-  ],
-  "resourceToTagIds": {
-    "1": [
-      1
-    ]
-  }
-}
\ No newline at end of file
diff --git a/storm-agent/src/test/resources/storm-policies.json b/storm-agent/src/test/resources/storm-policies.json
deleted file mode 100644
index b89410a3e..000000000
--- a/storm-agent/src/test/resources/storm-policies.json
+++ /dev/null
@@ -1,1147 +0,0 @@
-{
-  "serviceName": "cl1_storm",
-  "serviceId": 1,
-  "policyVersion": 9,
-  "policyUpdateTime": "20170307-11:42:26.000-+0000",
-  "policies": [
-    {
-      "service": "cl1_storm",
-      "name": "all - topology",
-      "policyType": 0,
-      "description": "Policy for all - topology",
-      "isAuditEnabled": true,
-      "resources": {
-        "topology": {
-          "values": [
-            "*"
-          ],
-          "isExcludes": false,
-          "isRecursive": false
-        }
-      },
-      "policyItems": [
-        {
-          "accesses": [
-            {
-              "type": "submitTopology",
-              "isAllowed": true
-            },
-            {
-              "type": "fileUpload",
-              "isAllowed": true
-            },
-            {
-              "type": "fileDownload",
-              "isAllowed": true
-            },
-            {
-              "type": "killTopology",
-              "isAllowed": true
-            },
-            {
-              "type": "rebalance",
-              "isAllowed": true
-            },
-            {
-              "type": "activate",
-              "isAllowed": true
-            },
-            {
-              "type": "deactivate",
-              "isAllowed": true
-            },
-            {
-              "type": "getTopologyConf",
-              "isAllowed": true
-            },
-            {
-              "type": "getTopology",
-              "isAllowed": true
-            },
-            {
-              "type": "getUserTopology",
-              "isAllowed": true
-            },
-            {
-              "type": "getTopologyInfo",
-              "isAllowed": true
-            },
-            {
-              "type": "uploadNewCredentials",
-              "isAllowed": true
-            }
-          ],
-          "users": [
-            "asf"
-          ],
-          "groups": [],
-          "conditions": [],
-          "delegateAdmin": true
-        }
-      ],
-      "denyPolicyItems": [],
-      "allowExceptions": [],
-      "denyExceptions": [],
-      "dataMaskPolicyItems": [],
-      "rowFilterPolicyItems": [],
-      "id": 1,
-      "isEnabled": true,
-      "version": 1
-    },
-    {
-      "service": "cl1_storm",
-      "name": "WordCountPolicy",
-      "policyType": 0,
-      "description": "",
-      "isAuditEnabled": true,
-      "resources": {
-        "topology": {
-          "values": [
-            "word-count"
-          ],
-          "isExcludes": false,
-          "isRecursive": false
-        }
-      },
-      "policyItems": [
-        {
-          "accesses": [
-            {
-              "type": "submitTopology",
-              "isAllowed": true
-            },
-            {
-              "type": "fileUpload",
-              "isAllowed": true
-            },
-            {
-              "type": "fileDownload",
-              "isAllowed": true
-            },
-            {
-              "type": "killTopology",
-              "isAllowed": true
-            },
-            {
-              "type": "rebalance",
-              "isAllowed": true
-            },
-            {
-              "type": "activate",
-              "isAllowed": true
-            },
-            {
-              "type": "deactivate",
-              "isAllowed": true
-            },
-            {
-              "type": "getTopologyConf",
-              "isAllowed": true
-            },
-            {
-              "type": "getTopology",
-              "isAllowed": true
-            },
-            {
-              "type": "getUserTopology",
-              "isAllowed": true
-            },
-            {
-              "type": "getTopologyInfo",
-              "isAllowed": true
-            },
-            {
-              "type": "uploadNewCredentials",
-              "isAllowed": true
-            }
-          ],
-          "users": [
-            "bob"
-          ],
-          "groups": [],
-          "conditions": [],
-          "delegateAdmin": false
-        }
-      ],
-      "denyPolicyItems": [],
-      "allowExceptions": [],
-      "denyExceptions": [],
-      "dataMaskPolicyItems": [],
-      "rowFilterPolicyItems": [],
-      "id": 2,
-      "isEnabled": true,
-      "version": 1
-    },
-    {
-      "service": "cl1_storm",
-      "name": "TempPolicy",
-      "policyType": 0,
-      "description": "",
-      "isAuditEnabled": true,
-      "resources": {
-        "topology": {
-          "values": [
-            "temp*"
-          ],
-          "isExcludes": false,
-          "isRecursive": false
-        }
-      },
-      "policyItems": [
-        {
-          "accesses": [
-            {
-              "type": "submitTopology",
-              "isAllowed": true
-            },
-            {
-              "type": "killTopology",
-              "isAllowed": true
-            }
-          ],
-          "users": [
-            "bob"
-          ],
-          "groups": [],
-          "conditions": [],
-          "delegateAdmin": false
-        }
-      ],
-      "denyPolicyItems": [],
-      "allowExceptions": [],
-      "denyExceptions": [],
-      "dataMaskPolicyItems": [],
-      "rowFilterPolicyItems": [],
-      "id": 3,
-      "isEnabled": true,
-      "version": 1
-    }
-  ],
-  "serviceDef": {
-    "name": "storm",
-    "implClass": "org.apache.ranger.services.storm.RangerServiceStorm",
-    "label": "Storm",
-    "description": "Storm",
-    "options": {},
-    "configs": [
-      {
-        "itemId": 1,
-        "name": "username",
-        "type": "string",
-        "mandatory": true,
-        "validationRegEx": "",
-        "validationMessage": "",
-        "uiHint": "",
-        "label": "Username"
-      },
-      {
-        "itemId": 2,
-        "name": "password",
-        "type": "password",
-        "mandatory": true,
-        "validationRegEx": "",
-        "validationMessage": "",
-        "uiHint": "",
-        "label": "Password"
-      },
-      {
-        "itemId": 3,
-        "name": "nimbus.url",
-        "type": "string",
-        "mandatory": true,
-        "defaultValue": "",
-        "validationRegEx": "",
-        "validationMessage": "",
-        "uiHint": "",
-        "label": "Nimbus URL"
-      },
-      {
-        "itemId": 4,
-        "name": "commonNameForCertificate",
-        "type": "string",
-        "mandatory": false,
-        "validationRegEx": "",
-        "validationMessage": "",
-        "uiHint": "",
-        "label": "Common Name for Certificate"
-      }
-    ],
-    "resources": [
-      {
-        "itemId": 1,
-        "name": "topology",
-        "type": "string",
-        "level": 10,
-        "mandatory": true,
-        "lookupSupported": true,
-        "recursiveSupported": false,
-        "excludesSupported": true,
-        "matcher": "org.apache.ranger.plugin.resourcematcher.RangerDefaultResourceMatcher",
-        "matcherOptions": {
-          "wildCard": "true",
-          "ignoreCase": "false"
-        },
-        "validationRegEx": "",
-        "validationMessage": "",
-        "uiHint": "",
-        "label": "Storm Topology",
-        "description": "Storm Topology"
-      }
-    ],
-    "accessTypes": [
-      {
-        "itemId": 1,
-        "name": "submitTopology",
-        "label": "Submit Topology",
-        "impliedGrants": [
-          "fileUpload",
-          "fileDownload"
-        ]
-      },
-      {
-        "itemId": 2,
-        "name": "fileUpload",
-        "label": "File Upload",
-        "impliedGrants": []
-      },
-      {
-        "itemId": 5,
-        "name": "fileDownload",
-        "label": "File Download",
-        "impliedGrants": []
-      },
-      {
-        "itemId": 6,
-        "name": "killTopology",
-        "label": "Kill Topology",
-        "impliedGrants": []
-      },
-      {
-        "itemId": 7,
-        "name": "rebalance",
-        "label": "Rebalance",
-        "impliedGrants": []
-      },
-      {
-        "itemId": 8,
-        "name": "activate",
-        "label": "Activate",
-        "impliedGrants": []
-      },
-      {
-        "itemId": 9,
-        "name": "deactivate",
-        "label": "Deactivate",
-        "impliedGrants": []
-      },
-      {
-        "itemId": 10,
-        "name": "getTopologyConf",
-        "label": "Get Topology Conf",
-        "impliedGrants": []
-      },
-      {
-        "itemId": 11,
-        "name": "getTopology",
-        "label": "Get Topology",
-        "impliedGrants": []
-      },
-      {
-        "itemId": 12,
-        "name": "getUserTopology",
-        "label": "Get User Topology",
-        "impliedGrants": []
-      },
-      {
-        "itemId": 13,
-        "name": "getTopologyInfo",
-        "label": "Get Topology Info",
-        "impliedGrants": []
-      },
-      {
-        "itemId": 14,
-        "name": "uploadNewCredentials",
-        "label": "Upload New Credential",
-        "impliedGrants": []
-      }
-    ],
-    "policyConditions": [],
-    "contextEnrichers": [],
-    "enums": [],
-    "dataMaskDef": {
-      "maskTypes": [],
-      "accessTypes": [],
-      "resources": []
-    },
-    "rowFilterDef": {
-      "accessTypes": [],
-      "resources": []
-    },
-    "id": 6,
-    "guid": "2a60f427-edcf-4e20-834c-a9a267b5b963",
-    "isEnabled": true,
-    "createTime": "20170302-11:21:21.000-+0000",
-    "updateTime": "20170302-11:21:21.000-+0000",
-    "version": 1
-  },
-  "auditMode": "audit-default",
-  "tagPolicies": {
-    "serviceName": "AtlasService",
-    "serviceId": 2,
-    "policyVersion": 7,
-    "policyUpdateTime": "20170307-11:42:26.000-+0000",
-    "policies": [
-      {
-        "service": "AtlasService",
-        "name": "EXPIRES_ON",
-        "policyType": 0,
-        "description": "Policy for data with EXPIRES_ON tag",
-        "isAuditEnabled": true,
-        "resources": {
-          "tag": {
-            "values": [
-              "EXPIRES_ON"
-            ],
-            "isExcludes": false,
-            "isRecursive": false
-          }
-        },
-        "policyItems": [],
-        "denyPolicyItems": [
-          {
-            "accesses": [
-              {
-                "type": "hdfs:read",
-                "isAllowed": true
-              },
-              {
-                "type": "hdfs:write",
-                "isAllowed": true
-              },
-              {
-                "type": "hdfs:execute",
-                "isAllowed": true
-              },
-              {
-                "type": "hbase:read",
-                "isAllowed": true
-              },
-              {
-                "type": "hbase:write",
-                "isAllowed": true
-              },
-              {
-                "type": "hbase:create",
-                "isAllowed": true
-              },
-              {
-                "type": "hbase:admin",
-                "isAllowed": true
-              },
-              {
-                "type": "hive:select",
-                "isAllowed": true
-              },
-              {
-                "type": "hive:update",
-                "isAllowed": true
-              },
-              {
-                "type": "hive:create",
-                "isAllowed": true
-              },
-              {
-                "type": "hive:drop",
-                "isAllowed": true
-              },
-              {
-                "type": "hive:alter",
-                "isAllowed": true
-              },
-              {
-                "type": "hive:index",
-                "isAllowed": true
-              },
-              {
-                "type": "hive:lock",
-                "isAllowed": true
-              },
-              {
-                "type": "hive:all",
-                "isAllowed": true
-              },
-              {
-                "type": "yarn:submit-app",
-                "isAllowed": true
-              },
-              {
-                "type": "yarn:admin-queue",
-                "isAllowed": true
-              },
-              {
-                "type": "knox:allow",
-                "isAllowed": true
-              },
-              {
-                "type": "storm:submitTopology",
-                "isAllowed": true
-              },
-              {
-                "type": "storm:fileUpload",
-                "isAllowed": true
-              },
-              {
-                "type": "storm:fileDownload",
-                "isAllowed": true
-              },
-              {
-                "type": "storm:killTopology",
-                "isAllowed": true
-              },
-              {
-                "type": "storm:rebalance",
-                "isAllowed": true
-              },
-              {
-                "type": "storm:activate",
-                "isAllowed": true
-              },
-              {
-                "type": "storm:deactivate",
-                "isAllowed": true
-              },
-              {
-                "type": "storm:getTopologyConf",
-                "isAllowed": true
-              },
-              {
-                "type": "storm:getTopology",
-                "isAllowed": true
-              },
-              {
-                "type": "storm:getUserTopology",
-                "isAllowed": true
-              },
-              {
-                "type": "storm:getTopologyInfo",
-                "isAllowed": true
-              },
-              {
-                "type": "storm:uploadNewCredentials",
-                "isAllowed": true
-              },
-              {
-                "type": "kms:create",
-                "isAllowed": true
-              },
-              {
-                "type": "kms:delete",
-                "isAllowed": true
-              },
-              {
-                "type": "kms:rollover",
-                "isAllowed": true
-              },
-              {
-                "type": "kms:setkeymaterial",
-                "isAllowed": true
-              },
-              {
-                "type": "kms:get",
-                "isAllowed": true
-              },
-              {
-                "type": "kms:getkeys",
-                "isAllowed": true
-              },
-              {
-                "type": "kms:getmetadata",
-                "isAllowed": true
-              },
-              {
-                "type": "kms:generateeek",
-                "isAllowed": true
-              },
-              {
-                "type": "kms:decrypteek",
-                "isAllowed": true
-              },
-              {
-                "type": "solr:query",
-                "isAllowed": true
-              },
-              {
-                "type": "solr:update",
-                "isAllowed": true
-              },
-              {
-                "type": "solr:others",
-                "isAllowed": true
-              },
-              {
-                "type": "solr:solr_admin",
-                "isAllowed": true
-              },
-              {
-                "type": "kafka:publish",
-                "isAllowed": true
-              },
-              {
-                "type": "kafka:consume",
-                "isAllowed": true
-              },
-              {
-                "type": "kafka:configure",
-                "isAllowed": true
-              },
-              {
-                "type": "kafka:describe",
-                "isAllowed": true
-              },
-              {
-                "type": "kafka:create",
-                "isAllowed": true
-              },
-              {
-                "type": "kafka:delete",
-                "isAllowed": true
-              },
-              {
-                "type": "kafka:kafka_admin",
-                "isAllowed": true
-              },
-              {
-                "type": "atlas:read",
-                "isAllowed": true
-              },
-              {
-                "type": "atlas:create",
-                "isAllowed": true
-              },
-              {
-                "type": "atlas:update",
-                "isAllowed": true
-              },
-              {
-                "type": "atlas:delete",
-                "isAllowed": true
-              },
-              {
-                "type": "atlas:all",
-                "isAllowed": true
-              }
-            ],
-            "users": [],
-            "groups": [
-              "public"
-            ],
-            "conditions": [
-              {
-                "type": "accessed-after-expiry",
-                "values": [
-                  "yes"
-                ]
-              }
-            ],
-            "delegateAdmin": false
-          }
-        ],
-        "allowExceptions": [],
-        "denyExceptions": [],
-        "dataMaskPolicyItems": [],
-        "rowFilterPolicyItems": [],
-        "id": 4,
-        "isEnabled": true,
-        "version": 1
-      },
-      {
-        "service": "AtlasService",
-        "name": "StormDevPolicy",
-        "policyType": 0,
-        "description": "",
-        "isAuditEnabled": true,
-        "resources": {
-          "tag": {
-            "values": [
-              "StormTopologyTag"
-            ],
-            "isExcludes": false,
-            "isRecursive": false
-          }
-        },
-        "policyItems": [
-          {
-            "accesses": [
-              {
-                "type": "storm:submitTopology",
-                "isAllowed": true
-              },
-              {
-                "type": "storm:killTopology",
-                "isAllowed": true
-              }
-            ],
-            "users": [
-              "bob"
-            ],
-            "groups": [],
-            "conditions": [],
-            "delegateAdmin": false
-          }
-        ],
-        "denyPolicyItems": [],
-        "allowExceptions": [],
-        "denyExceptions": [],
-        "dataMaskPolicyItems": [],
-        "rowFilterPolicyItems": [],
-        "id": 5,
-        "isEnabled": true,
-        "version": 5
-      }
-    ],
-    "serviceDef": {
-      "name": "tag",
-      "implClass": "org.apache.ranger.services.tag.RangerServiceTag",
-      "label": "TAG",
-      "description": "TAG Service Definition",
-      "options": {
-        "ui.pages": "tag-based-policies"
-      },
-      "configs": [],
-      "resources": [
-        {
-          "itemId": 1,
-          "name": "tag",
-          "type": "string",
-          "level": 1,
-          "mandatory": true,
-          "lookupSupported": true,
-          "recursiveSupported": false,
-          "excludesSupported": false,
-          "matcher": "org.apache.ranger.plugin.resourcematcher.RangerDefaultResourceMatcher",
-          "matcherOptions": {
-            "wildCard": "false",
-            "ignoreCase": "false"
-          },
-          "validationRegEx": "",
-          "validationMessage": "",
-          "uiHint": "{ \"singleValue\":true }",
-          "label": "TAG",
-          "description": "TAG"
-        }
-      ],
-      "accessTypes": [
-        {
-          "itemId": 1002,
-          "name": "hdfs:read",
-          "label": "Read",
-          "impliedGrants": []
-        },
-        {
-          "itemId": 1003,
-          "name": "hdfs:write",
-          "label": "Write",
-          "impliedGrants": []
-        },
-        {
-          "itemId": 1004,
-          "name": "hdfs:execute",
-          "label": "Execute",
-          "impliedGrants": []
-        },
-        {
-          "itemId": 2003,
-          "name": "hbase:read",
-          "label": "Read",
-          "impliedGrants": []
-        },
-        {
-          "itemId": 2004,
-          "name": "hbase:write",
-          "label": "Write",
-          "impliedGrants": []
-        },
-        {
-          "itemId": 2005,
-          "name": "hbase:create",
-          "label": "Create",
-          "impliedGrants": []
-        },
-        {
-          "itemId": 2006,
-          "name": "hbase:admin",
-          "label": "Admin",
-          "impliedGrants": [
-            "hbase:read",
-            "hbase:write",
-            "hbase:create"
-          ]
-        },
-        {
-          "itemId": 3004,
-          "name": "hive:select",
-          "label": "select",
-          "impliedGrants": []
-        },
-        {
-          "itemId": 3005,
-          "name": "hive:update",
-          "label": "update",
-          "impliedGrants": []
-        },
-        {
-          "itemId": 3006,
-          "name": "hive:create",
-          "label": "Create",
-          "impliedGrants": []
-        },
-        {
-          "itemId": 3007,
-          "name": "hive:drop",
-          "label": "Drop",
-          "impliedGrants": []
-        },
-        {
-          "itemId": 3008,
-          "name": "hive:alter",
-          "label": "Alter",
-          "impliedGrants": []
-        },
-        {
-          "itemId": 3009,
-          "name": "hive:index",
-          "label": "Index",
-          "impliedGrants": []
-        },
-        {
-          "itemId": 3010,
-          "name": "hive:lock",
-          "label": "Lock",
-          "impliedGrants": []
-        },
-        {
-          "itemId": 3011,
-          "name": "hive:all",
-          "label": "All",
-          "impliedGrants": [
-            "hive:select",
-            "hive:update",
-            "hive:create",
-            "hive:drop",
-            "hive:alter",
-            "hive:index",
-            "hive:lock"
-          ]
-        },
-        {
-          "itemId": 4005,
-          "name": "yarn:submit-app",
-          "label": "submit-app",
-          "impliedGrants": []
-        },
-        {
-          "itemId": 4006,
-          "name": "yarn:admin-queue",
-          "label": "admin-queue",
-          "impliedGrants": [
-            "yarn:submit-app"
-          ]
-        },
-        {
-          "itemId": 5006,
-          "name": "knox:allow",
-          "label": "Allow",
-          "impliedGrants": []
-        },
-        {
-          "itemId": 6007,
-          "name": "storm:submitTopology",
-          "label": "Submit Topology",
-          "impliedGrants": [
-            "storm:fileUpload",
-            "storm:fileDownload"
-          ]
-        },
-        {
-          "itemId": 6008,
-          "name": "storm:fileUpload",
-          "label": "File Upload",
-          "impliedGrants": []
-        },
-        {
-          "itemId": 6011,
-          "name": "storm:fileDownload",
-          "label": "File Download",
-          "impliedGrants": []
-        },
-        {
-          "itemId": 6012,
-          "name": "storm:killTopology",
-          "label": "Kill Topology",
-          "impliedGrants": []
-        },
-        {
-          "itemId": 6013,
-          "name": "storm:rebalance",
-          "label": "Rebalance",
-          "impliedGrants": []
-        },
-        {
-          "itemId": 6014,
-          "name": "storm:activate",
-          "label": "Activate",
-          "impliedGrants": []
-        },
-        {
-          "itemId": 6015,
-          "name": "storm:deactivate",
-          "label": "Deactivate",
-          "impliedGrants": []
-        },
-        {
-          "itemId": 6016,
-          "name": "storm:getTopologyConf",
-          "label": "Get Topology Conf",
-          "impliedGrants": []
-        },
-        {
-          "itemId": 6017,
-          "name": "storm:getTopology",
-          "label": "Get Topology",
-          "impliedGrants": []
-        },
-        {
-          "itemId": 6018,
-          "name": "storm:getUserTopology",
-          "label": "Get User Topology",
-          "impliedGrants": []
-        },
-        {
-          "itemId": 6019,
-          "name": "storm:getTopologyInfo",
-          "label": "Get Topology Info",
-          "impliedGrants": []
-        },
-        {
-          "itemId": 6020,
-          "name": "storm:uploadNewCredentials",
-          "label": "Upload New Credential",
-          "impliedGrants": []
-        },
-        {
-          "itemId": 7008,
-          "name": "kms:create",
-          "label": "Create",
-          "impliedGrants": []
-        },
-        {
-          "itemId": 7009,
-          "name": "kms:delete",
-          "label": "Delete",
-          "impliedGrants": []
-        },
-        {
-          "itemId": 7010,
-          "name": "kms:rollover",
-          "label": "Rollover",
-          "impliedGrants": []
-        },
-        {
-          "itemId": 7011,
-          "name": "kms:setkeymaterial",
-          "label": "Set Key Material",
-          "impliedGrants": []
-        },
-        {
-          "itemId": 7012,
-          "name": "kms:get",
-          "label": "Get",
-          "impliedGrants": []
-        },
-        {
-          "itemId": 7013,
-          "name": "kms:getkeys",
-          "label": "Get Keys",
-          "impliedGrants": []
-        },
-        {
-          "itemId": 7014,
-          "name": "kms:getmetadata",
-          "label": "Get Metadata",
-          "impliedGrants": []
-        },
-        {
-          "itemId": 7015,
-          "name": "kms:generateeek",
-          "label": "Generate EEK",
-          "impliedGrants": []
-        },
-        {
-          "itemId": 7016,
-          "name": "kms:decrypteek",
-          "label": "Decrypt EEK",
-          "impliedGrants": []
-        },
-        {
-          "itemId": 8108,
-          "name": "solr:query",
-          "label": "Query",
-          "impliedGrants": []
-        },
-        {
-          "itemId": 8208,
-          "name": "solr:update",
-          "label": "Update",
-          "impliedGrants": []
-        },
-        {
-          "itemId": 8308,
-          "name": "solr:others",
-          "label": "Others",
-          "impliedGrants": []
-        },
-        {
-          "itemId": 8908,
-          "name": "solr:solr_admin",
-          "label": "Solr Admin",
-          "impliedGrants": [
-            "solr:query",
-            "solr:update",
-            "solr:others"
-          ]
-        },
-        {
-          "itemId": 9010,
-          "name": "kafka:publish",
-          "label": "Publish",
-          "impliedGrants": [
-            "kafka:describe"
-          ]
-        },
-        {
-          "itemId": 9011,
-          "name": "kafka:consume",
-          "label": "Consume",
-          "impliedGrants": [
-            "kafka:describe"
-          ]
-        },
-        {
-          "itemId": 9014,
-          "name": "kafka:configure",
-          "label": "Configure",
-          "impliedGrants": [
-            "kafka:describe"
-          ]
-        },
-        {
-          "itemId": 9015,
-          "name": "kafka:describe",
-          "label": "Describe",
-          "impliedGrants": []
-        },
-        {
-          "itemId": 9017,
-          "name": "kafka:create",
-          "label": "Create",
-          "impliedGrants": []
-        },
-        {
-          "itemId": 9018,
-          "name": "kafka:delete",
-          "label": "Delete",
-          "impliedGrants": []
-        },
-        {
-          "itemId": 9016,
-          "name": "kafka:kafka_admin",
-          "label": "Kafka Admin",
-          "impliedGrants": [
-            "kafka:publish",
-            "kafka:consume",
-            "kafka:configure",
-            "kafka:describe",
-            "kafka:create",
-            "kafka:delete"
-          ]
-        },
-        {
-          "itemId": 11012,
-          "name": "atlas:read",
-          "label": "read",
-          "impliedGrants": []
-        },
-        {
-          "itemId": 11013,
-          "name": "atlas:create",
-          "label": "create",
-          "impliedGrants": []
-        },
-        {
-          "itemId": 11014,
-          "name": "atlas:update",
-          "label": "update",
-          "impliedGrants": []
-        },
-        {
-          "itemId": 11015,
-          "name": "atlas:delete",
-          "label": "delete",
-          "impliedGrants": []
-        },
-        {
-          "itemId": 11016,
-          "name": "atlas:all",
-          "label": "All",
-          "impliedGrants": [
-            "atlas:read",
-            "atlas:create",
-            "atlas:update",
-            "atlas:delete"
-          ]
-        }
-      ],
-      "policyConditions": [
-        {
-          "itemId": 1,
-          "name": "accessed-after-expiry",
-          "evaluator": "org.apache.ranger.plugin.conditionevaluator.RangerScriptTemplateConditionEvaluator",
-          "evaluatorOptions": {
-            "scriptTemplate": "ctx.isAccessedAfter(\u0027expiry_date\u0027);"
-          },
-          "uiHint": "{ \"singleValue\":true }",
-          "label": "Accessed after expiry_date (yes/no)?",
-          "description": "Accessed after expiry_date? (yes/no)"
-        }
-      ],
-      "contextEnrichers": [
-        {
-          "itemId": 1,
-          "name": "TagEnricher",
-          "enricher": "org.apache.ranger.plugin.contextenricher.RangerTagEnricher",
-          "enricherOptions": {
-            "tagRetrieverClassName": "org.apache.ranger.plugin.contextenricher.RangerAdminTagRetriever",
-            "tagRefresherPollingInterval": "60000"
-          }
-        }
-      ],
-      "enums": [],
-      "dataMaskDef": {
-        "maskTypes": [],
-        "accessTypes": [],
-        "resources": []
-      },
-      "rowFilterDef": {
-        "accessTypes": [],
-        "resources": []
-      },
-      "id": 100,
-      "guid": "0d047248-baff-4cf9-8e9e-d5d377284b2e",
-      "isEnabled": true,
-      "createTime": "20170302-11:21:21.000-+0000",
-      "updateTime": "20170302-11:21:23.000-+0000",
-      "version": 11
-    },
-    "auditMode": "audit-default"
-  }
-}
\ No newline at end of file
diff --git a/storm-agent/src/test/resources/storm.yaml b/storm-agent/src/test/resources/storm.yaml
deleted file mode 100644
index 482cbf700..000000000
--- a/storm-agent/src/test/resources/storm.yaml
+++ /dev/null
@@ -1,25 +0,0 @@
-# Licensed to the Apache Software Foundation (ASF) under one
-# or more contributor license agreements.  See the NOTICE file
-# distributed with this work for additional information
-# regarding copyright ownership.  The ASF licenses this file
-# to you under the Apache License, Version 2.0 (the
-# "License"); you may not use this file except in compliance
-# with the License.  You may obtain a copy of the License at
-#
-# http://www.apache.org/licenses/LICENSE-2.0
-#
-# Unless required by applicable law or agreed to in writing, software
-# distributed under the License is distributed on an "AS IS" BASIS,
-# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-# See the License for the specific language governing permissions and
-# limitations under the License.
-
-
-########### These all have default values as shown
-########### Additional configuration goes into storm.yaml
-
-storm.zookeeper.servers:
-    - "localhost"
-nimbus.seeds : ["localhost"]
-# Plug in ranger nimbus.authorizer here
-nimbus.authorizer: "org.apache.ranger.authorization.storm.authorizer.RangerStormAuthorizer"
diff --git a/storm-agent/src/test/resources/words.txt b/storm-agent/src/test/resources/words.txt
deleted file mode 100644
index c7725df8b..000000000
--- a/storm-agent/src/test/resources/words.txt
+++ /dev/null
@@ -1,27 +0,0 @@
-﻿# Licensed to the Apache Software Foundation (ASF) under one
-# or more contributor license agreements.  See the NOTICE file
-# distributed with this work for additional information
-# regarding copyright ownership.  The ASF licenses this file
-# to you under the Apache License, Version 2.0 (the
-# "License"); you may not use this file except in compliance
-# with the License.  You may obtain a copy of the License at
-#
-# http://www.apache.org/licenses/LICENSE-2.0
-#
-# Unless required by applicable law or agreed to in writing, software
-# distributed under the License is distributed on an "AS IS" BASIS,
-# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-# See the License for the specific language governing permissions and
-# limitations under the License.
-the
-and
-storm
-random
-word
-spout
-test
-apache
-the
-spoon
-and
-the
\ No newline at end of file
